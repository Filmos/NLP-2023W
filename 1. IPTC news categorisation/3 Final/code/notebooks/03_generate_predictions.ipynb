{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from src.embeddings import OpenaiAdaEmbedding, BertEmbedding, AngleEmbedding, MiniLMEmbedding\n",
    "from src.exploratory_data_analysis import gather_data\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we instantiate classes responsible for gathering:\n",
    "1. Ada Embeddings from OpenAI API\n",
    "2. Embeddings from `bert-base-uncased` BERT architecture \n",
    "3. Embeddings from open-source, state-of-the-art UAE-Large-V1 model https://huggingface.co/WhereIsAI/UAE-Large-V1\n",
    "\n",
    "To generate Ada Embeddings, an openai_key is needed. One can create such key at https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "openai_embedding = OpenaiAdaEmbedding(api_key)\n",
    "bert_embedding = BertEmbedding(model_name='bert-base-uncased')\n",
    "angle_embedding = AngleEmbedding()\n",
    "mini_lm_embeddig = MiniLMEmbedding()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create embeddings for instances present in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('../data/test_sets/test_set_random.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 10 minutes of computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['ada_embedding'] = test_set['text'].apply(openai_embedding.get_embedding)\n",
    "test_set['angle_embedding'] = test_set['text'].apply(angle_embedding.get_embedding).apply(lambda x: x.tolist())\n",
    "test_set['mini_lm_embedding'] = test_set['text'].apply(mini_lm_embeddig.get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('../data/test_sets/test_set_random_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we load csv files containing taxonomies and embeddings of IPTC categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_ada = pd.read_csv('../data/taxonomy/embeddings/taxonomy_openai_ada.csv')\n",
    "taxonomy_angle = pd.read_csv('../data/taxonomy/embeddings/taxonomy_angle.csv')\n",
    "taxonomy_mini_lm = pd.read_csv('../data/taxonomy/embeddings/taxonomy_mini_lm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform classification based on cosine similarity. More explicitly, for each news article an IPTC category with highest cosine similarity is chosen as its label."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enclose the classification method inside a function. \n",
    "1. It reads article and taxonomy embeddings and saves them to numpy array. \n",
    "2. Creates cosine similarity matrix between article and names (descriptions) of category embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(df_articles, df_taxonomy, column_name_article_embedding, column_name_category_embedding):\n",
    "    \"\"\"Classifies articles based on the taxonomy.\n",
    "    \n",
    "    Args:\n",
    "        df_articles (pd.DataFrame): Dataframe containing the articles.\n",
    "        df_taxonomy (pd.DataFrame): Dataframe containing the taxonomy.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing the articles with the predicted categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    article_embeddings = df_articles[column_name_article_embedding]\n",
    "    category_embeddings = df_taxonomy[column_name_category_embedding]\n",
    "    \n",
    "    if isinstance(article_embeddings.iloc[0], str):\n",
    "        article_embeddings = article_embeddings.apply(eval)\n",
    "    \n",
    "    if isinstance(category_embeddings.iloc[0], str):\n",
    "        category_embeddings = category_embeddings.apply(eval)\n",
    "    \n",
    "    article_embeddings = np.array(article_embeddings.tolist())\n",
    "    category_embeddings = np.array(category_embeddings.tolist())\n",
    "    \n",
    "    # compute similarity matrix of each article to each category\n",
    "    similarity_scores = cosine_similarity(article_embeddings, category_embeddings)\n",
    "    probabilities = similarity_scores / similarity_scores.sum(axis=1, keepdims=True)\n",
    "    preds = np.argmax(probabilities, axis=1)\n",
    "    preds_names = df_taxonomy['name'].iloc[preds].values\n",
    "    \n",
    "    # create output dataframe\n",
    "    df_output = df_articles.copy()\n",
    "    df_output['predicted_category_name'] = preds_names\n",
    "    df_output['predicted_category_number'] = preds\n",
    "    df_output['predicted_category_probability'] = np.max(probabilities, axis=1)\n",
    "    df_output['predicted_categories_all_probabilities'] = [str(list(probs)) for probs in probabilities]\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for 1st hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we experiment only with Ada Embeddings and at first, only top-level hierarchy from IPTC categories is considered. It is due to number of reasons:\n",
    "1. It is much easier to create test set for classification problem with 18 categories (number of top-level categories), in comparison to over 900 all categories\n",
    "2. We want to verify general understanding of the method based on cosine similarity, and if the results are promising, generalize it for more IPTC categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_name_hierarchy_1 = generate_predictions(test_set, taxonomy_ada[taxonomy_ada['hierarchy'] == 1], 'ada_embedding', 'embedding_name')\n",
    "ada_description_hierarchy_1 = generate_predictions(test_set, taxonomy_ada[taxonomy_ada['hierarchy'] == 1], 'ada_embedding', 'embedding_description')\n",
    "\n",
    "angle_name_hierarchy_1 = generate_predictions(test_set, taxonomy_angle[taxonomy_angle['hierarchy'] == 1], 'angle_embedding', 'embedding_name')\n",
    "angle_description_hierarchy_1 = generate_predictions(test_set, taxonomy_angle[taxonomy_angle['hierarchy'] == 1], 'angle_embedding', 'embedding_description')\n",
    "\n",
    "mini_lm_name_hierarchy_1 = generate_predictions(test_set, taxonomy_mini_lm[taxonomy_mini_lm['hierarchy'] == 1], 'mini_lm_embedding', 'embedding_name')\n",
    "mini_lm_description_hierarchy_1 = generate_predictions(test_set, taxonomy_mini_lm[taxonomy_mini_lm['hierarchy'] == 1], 'mini_lm_embedding', 'embedding_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_name_hierarchy_1.to_csv('../results/top_hierarchy/ada_name.csv', index=False)\n",
    "ada_description_hierarchy_1.to_csv('../results/top_hierarchy/ada_description.csv', index=False)\n",
    "\n",
    "angle_name_hierarchy_1.to_csv('../results/top_hierarchy/angle_name.csv', index=False)\n",
    "angle_description_hierarchy_1.to_csv('../results/top_hierarchy/angle_description.csv', index=False)\n",
    "\n",
    "mini_lm_name_hierarchy_1.to_csv('../results/top_hierarchy/mini_lm_name.csv', index=False)\n",
    "mini_lm_description_hierarchy_1.to_csv('../results/top_hierarchy/mini_lm_description.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for all hierarchies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also experimet with lower level hierarchies combined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_name = generate_predictions(test_set, taxonomy_ada, 'ada_embedding', 'embedding_name')\n",
    "ada_description = generate_predictions(test_set, taxonomy_ada, 'ada_embedding', 'embedding_description')\n",
    "\n",
    "angle_name = generate_predictions(test_set, taxonomy_angle, 'angle_embedding', 'embedding_name')\n",
    "angle_description = generate_predictions(test_set, taxonomy_angle, 'angle_embedding', 'embedding_description')\n",
    "\n",
    "mini_lm_name = generate_predictions(test_set, taxonomy_mini_lm, 'mini_lm_embedding', 'embedding_name')\n",
    "mini_lm_description = generate_predictions(test_set, taxonomy_mini_lm, 'mini_lm_embedding', 'embedding_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_name.to_csv('../results/all_hierarchies/ada_name.csv', index=False)\n",
    "ada_description.to_csv('../results/all_hierarchies/ada_description.csv', index=False)\n",
    "\n",
    "angle_name.to_csv('../results/all_hierarchies/angle_name.csv', index=False)\n",
    "angle_description.to_csv('../results/all_hierarchies/angle_description.csv', index=False)\n",
    "\n",
    "mini_lm_name.to_csv('../results/all_hierarchies/mini_lm_name.csv', index=False)\n",
    "mini_lm_description.to_csv('../results/all_hierarchies/mini_lm_description.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the results by briefly looking at the assigned categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>lede</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZPIZ proposes 3.5% extraordinary pension increase</td>\n",
       "      <td>The council of the public pension fund ZPIZ ha...</td>\n",
       "      <td>The extraordinary adjustment will apply from 1...</td>\n",
       "      <td>pension and welfare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two more convicted in Celje court leak case</td>\n",
       "      <td>Two more persons have been found guilty in a c...</td>\n",
       "      <td>Gregor Tanšek was found guilty of sharing clas...</td>\n",
       "      <td>prisoners and detainees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Municipalities report EUR 2.7 billion in flood...</td>\n",
       "      <td>Municipalities have reported over EUR 2.7 bill...</td>\n",
       "      <td>The forms sent through the Ajda web applicatio...</td>\n",
       "      <td>government aid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Večer says employer reps in the wrong about la...</td>\n",
       "      <td>Reflecting on the indignation of employer repr...</td>\n",
       "      <td>\"We've been hearing incessant reports about ho...</td>\n",
       "      <td>public employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ljubljana-based IRCAI partners with Amazon to ...</td>\n",
       "      <td>The Slovenia-based International Research Cent...</td>\n",
       "      <td>IRCAI is the only centre under the auspices of...</td>\n",
       "      <td>computing and information technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pride Parade organisers critical of police han...</td>\n",
       "      <td>The Pride Parade association was critical on W...</td>\n",
       "      <td>Muršec said that 3,500 people had taken part i...</td>\n",
       "      <td>gays and lesbians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Festival highlights city theatres of former Yu...</td>\n",
       "      <td>The Ruta Grupa Triglav travelling theatre fest...</td>\n",
       "      <td>The programme will open with the drama The Cel...</td>\n",
       "      <td>film festival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Suicide on slight downward trend, but preventi...</td>\n",
       "      <td>A total of 402 people in Slovenia committed su...</td>\n",
       "      <td>During the nine-year period, the suicide quoti...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Slovenia commemorates WWII resistance movement</td>\n",
       "      <td>Slovenia marks Day of Uprising Against Occupat...</td>\n",
       "      <td>This year's main ceremony was held on the eve ...</td>\n",
       "      <td>rebellions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Leak source at Krško N-plant identified, issue...</td>\n",
       "      <td>The Krško nuclear power plant (NEK) said it ha...</td>\n",
       "      <td>As representatives of the Nuclear Safety Admin...</td>\n",
       "      <td>nuclear accident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  ZPIZ proposes 3.5% extraordinary pension increase   \n",
       "1        Two more convicted in Celje court leak case   \n",
       "2  Municipalities report EUR 2.7 billion in flood...   \n",
       "3  Večer says employer reps in the wrong about la...   \n",
       "4  Ljubljana-based IRCAI partners with Amazon to ...   \n",
       "5  Pride Parade organisers critical of police han...   \n",
       "6  Festival highlights city theatres of former Yu...   \n",
       "7  Suicide on slight downward trend, but preventi...   \n",
       "8     Slovenia commemorates WWII resistance movement   \n",
       "9  Leak source at Krško N-plant identified, issue...   \n",
       "\n",
       "                                                lede  \\\n",
       "0  The council of the public pension fund ZPIZ ha...   \n",
       "1  Two more persons have been found guilty in a c...   \n",
       "2  Municipalities have reported over EUR 2.7 bill...   \n",
       "3  Reflecting on the indignation of employer repr...   \n",
       "4  The Slovenia-based International Research Cent...   \n",
       "5  The Pride Parade association was critical on W...   \n",
       "6  The Ruta Grupa Triglav travelling theatre fest...   \n",
       "7  A total of 402 people in Slovenia committed su...   \n",
       "8  Slovenia marks Day of Uprising Against Occupat...   \n",
       "9  The Krško nuclear power plant (NEK) said it ha...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The extraordinary adjustment will apply from 1...   \n",
       "1  Gregor Tanšek was found guilty of sharing clas...   \n",
       "2  The forms sent through the Ajda web applicatio...   \n",
       "3  \"We've been hearing incessant reports about ho...   \n",
       "4  IRCAI is the only centre under the auspices of...   \n",
       "5  Muršec said that 3,500 people had taken part i...   \n",
       "6  The programme will open with the drama The Cel...   \n",
       "7  During the nine-year period, the suicide quoti...   \n",
       "8  This year's main ceremony was held on the eve ...   \n",
       "9  As representatives of the Nuclear Safety Admin...   \n",
       "\n",
       "                predicted_category_name  \n",
       "0                   pension and welfare  \n",
       "1               prisoners and detainees  \n",
       "2                        government aid  \n",
       "3                      public employees  \n",
       "4  computing and information technology  \n",
       "5                     gays and lesbians  \n",
       "6                         film festival  \n",
       "7                               suicide  \n",
       "8                            rebellions  \n",
       "9                      nuclear accident  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_name[['headline', 'lede', 'text', 'predicted_category_name']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `data/articles_2023_en` dataset is too large to store on Github repository, we also assign labels to each separate dataframe from `data/2023_articles_en` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions2(df_articles, df_taxonomy, column_name_article_embedding, column_name_category_embedding):\n",
    "    \"\"\"Classifies articles based on the taxonomy.\n",
    "    \n",
    "    Args:\n",
    "        df_articles (pd.DataFrame): Dataframe containing the articles.\n",
    "        df_taxonomy (pd.DataFrame): Dataframe containing the taxonomy.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing the articles with the predicted categories.\n",
    "    \"\"\"\n",
    "    \n",
    "    article_embeddings = df_articles[column_name_article_embedding]\n",
    "    category_embeddings = df_taxonomy[column_name_category_embedding]\n",
    "    \n",
    "    if isinstance(article_embeddings.iloc[0], str):\n",
    "        article_embeddings = article_embeddings.apply(eval)\n",
    "    \n",
    "    if isinstance(category_embeddings.iloc[0], str):\n",
    "        category_embeddings = category_embeddings.apply(eval)\n",
    "    \n",
    "    article_embeddings = np.array(article_embeddings.tolist())\n",
    "    category_embeddings = np.array(category_embeddings.tolist())\n",
    "    \n",
    "    # compute similarity matrix of each article to each category\n",
    "    similarity_scores = cosine_similarity(article_embeddings, category_embeddings)\n",
    "    highest_similarity_scores = np.max(similarity_scores, axis=1)\n",
    "    probabilities = similarity_scores / similarity_scores.sum(axis=1, keepdims=True)\n",
    "    preds = np.argmax(probabilities, axis=1)\n",
    "    preds_names = df_taxonomy['name'].iloc[preds].values\n",
    "    \n",
    "    return preds_names, highest_similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [31:36<00:00, 189.65s/it]\n"
     ]
    }
   ],
   "source": [
    "path = '../data/2023_articles_en'\n",
    "\n",
    "for folder in tqdm(os.listdir(path)):\n",
    "    for filename in os.listdir(f'{path}/{folder}'):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            taxonomy = pd.read_csv('../data/taxonomy/embeddings/taxonomy_openai_ada.csv')\n",
    "            df = pd.read_csv(f'{path}/{folder}/{filename}')\n",
    "            df['high_label'], df['high_label_similarity'] = generate_predictions2(df, taxonomy[taxonomy['hierarchy'] == 1], 'ada_embedding', 'embedding_name')\n",
    "            df['mid_label'], df['mid_label_similarity'] = generate_predictions2(df, taxonomy[taxonomy['hierarchy'] == 2], 'ada_embedding', 'embedding_name')\n",
    "            df['label'], df['label_similarity'] = generate_predictions2(df, taxonomy, 'ada_embedding', 'embedding_name')\n",
    "            df.to_csv(f'{path}/{folder}/{filename}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Mar  1 2023, 18:23:06) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "27faff4ef72894b3e7b8600d716c9b98411577997f0c458edd4af7acfe033a25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
