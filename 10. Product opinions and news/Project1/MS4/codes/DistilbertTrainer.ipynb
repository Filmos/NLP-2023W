{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Dataset and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/amazon_electronics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.__len__(), test_df.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add new sentiment column to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentiment'] = train_df['overall'].apply(lambda x: 0 if x < 3 else (2 if x > 3 else 1))\n",
    "test_df['sentiment'] = test_df['overall'].apply(lambda x: 0 if x < 3 else (2 if x > 3 else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>2726396</td>\n",
       "      <td>B00877ZOYK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I received this product promptly from Amazon o...</td>\n",
       "      <td>Less than four months old, and a flaw in the p...</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>6205902</td>\n",
       "      <td>B0018Z2YA0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I'm using this device on a fairly new Dell Stu...</td>\n",
       "      <td>Works, But Inconvenient, With Poor Mic, Interf...</td>\n",
       "      <td>2993.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>487826</td>\n",
       "      <td>B000GAUZFO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have been using this with my nano for about ...</td>\n",
       "      <td>Don't believe the hype.</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>555634</td>\n",
       "      <td>B000JNYWBG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>As a dedicated iPod owner I was thrilled to le...</td>\n",
       "      <td>PRICEY AND SUFFERS FROM BUGS...</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4101812</td>\n",
       "      <td>B00IM7KYMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wow, this might be the worst purchase I've eve...</td>\n",
       "      <td>Poor performance, poorly constructed, bad qual...</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        asin  overall  \\\n",
       "1375     2726396  B00877ZOYK      2.0   \n",
       "2680     6205902  B0018Z2YA0      3.0   \n",
       "42        487826  B000GAUZFO      1.0   \n",
       "1495      555634  B000JNYWBG      2.0   \n",
       "295      4101812  B00IM7KYMC      1.0   \n",
       "\n",
       "                                             reviewText  \\\n",
       "1375  I received this product promptly from Amazon o...   \n",
       "2680  I'm using this device on a fairly new Dell Stu...   \n",
       "42    I have been using this with my nano for about ...   \n",
       "1495  As a dedicated iPod owner I was thrilled to le...   \n",
       "295   Wow, this might be the worst purchase I've eve...   \n",
       "\n",
       "                                                summary  Review_Length  \\\n",
       "1375  Less than four months old, and a flaw in the p...         2668.0   \n",
       "2680  Works, But Inconvenient, With Poor Mic, Interf...         2993.0   \n",
       "42                              Don't believe the hype.         5923.0   \n",
       "1495                    PRICEY AND SUFFERS FROM BUGS...         3070.0   \n",
       "295   Poor performance, poorly constructed, bad qual...         2534.0   \n",
       "\n",
       "      sentiment  \n",
       "1375          0  \n",
       "2680          1  \n",
       "42            0  \n",
       "1495          0  \n",
       "295           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add sentiment label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_int2str(row):\n",
    "    if row == 0:\n",
    "        return 'negative'\n",
    "    elif row == 1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>2726396</td>\n",
       "      <td>B00877ZOYK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I received this product promptly from Amazon o...</td>\n",
       "      <td>Less than four months old, and a flaw in the p...</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>6205902</td>\n",
       "      <td>B0018Z2YA0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I'm using this device on a fairly new Dell Stu...</td>\n",
       "      <td>Works, But Inconvenient, With Poor Mic, Interf...</td>\n",
       "      <td>2993.0</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>487826</td>\n",
       "      <td>B000GAUZFO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have been using this with my nano for about ...</td>\n",
       "      <td>Don't believe the hype.</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>555634</td>\n",
       "      <td>B000JNYWBG</td>\n",
       "      <td>2.0</td>\n",
       "      <td>As a dedicated iPod owner I was thrilled to le...</td>\n",
       "      <td>PRICEY AND SUFFERS FROM BUGS...</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4101812</td>\n",
       "      <td>B00IM7KYMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wow, this might be the worst purchase I've eve...</td>\n",
       "      <td>Poor performance, poorly constructed, bad qual...</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        asin  overall  \\\n",
       "1375     2726396  B00877ZOYK      2.0   \n",
       "2680     6205902  B0018Z2YA0      3.0   \n",
       "42        487826  B000GAUZFO      1.0   \n",
       "1495      555634  B000JNYWBG      2.0   \n",
       "295      4101812  B00IM7KYMC      1.0   \n",
       "\n",
       "                                             reviewText  \\\n",
       "1375  I received this product promptly from Amazon o...   \n",
       "2680  I'm using this device on a fairly new Dell Stu...   \n",
       "42    I have been using this with my nano for about ...   \n",
       "1495  As a dedicated iPod owner I was thrilled to le...   \n",
       "295   Wow, this might be the worst purchase I've eve...   \n",
       "\n",
       "                                                summary  Review_Length  \\\n",
       "1375  Less than four months old, and a flaw in the p...         2668.0   \n",
       "2680  Works, But Inconvenient, With Poor Mic, Interf...         2993.0   \n",
       "42                              Don't believe the hype.         5923.0   \n",
       "1495                    PRICEY AND SUFFERS FROM BUGS...         3070.0   \n",
       "295   Poor performance, poorly constructed, bad qual...         2534.0   \n",
       "\n",
       "      sentiment sentiment_name  \n",
       "1375          0       negative  \n",
       "2680          1        neutral  \n",
       "42            0       negative  \n",
       "1495          0       negative  \n",
       "295           0       negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"sentiment_name\"] = train_df['sentiment'].apply(lambda row: label_int2str(row))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>5959227</td>\n",
       "      <td>B01DWDEC4G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is an extreme disappointment. I purchased...</td>\n",
       "      <td>25 Mile Range Max</td>\n",
       "      <td>3865.0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>281023</td>\n",
       "      <td>B0002SQ2P2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I've had these speakers for about six weeks an...</td>\n",
       "      <td>Great hassle free 2.1 system at a great price</td>\n",
       "      <td>5279.0</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>53772</td>\n",
       "      <td>B000051SD1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I'm a drummer and have been involved with musi...</td>\n",
       "      <td>The Truth about these Headphones...</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>2605445</td>\n",
       "      <td>B007G51VEQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>First I must thank Amazon for their exceptiona...</td>\n",
       "      <td>Leading hardware and BIOS design - you get wha...</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>3717777</td>\n",
       "      <td>B00F415LEU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Let me preface this review by saying for a lon...</td>\n",
       "      <td>Unexpectedly brilliant, at least for an iOS de...</td>\n",
       "      <td>16996.0</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        asin  overall  \\\n",
       "508      5959227  B01DWDEC4G      1.0   \n",
       "3197      281023  B0002SQ2P2      4.0   \n",
       "2863       53772  B000051SD1      3.0   \n",
       "4570     2605445  B007G51VEQ      5.0   \n",
       "3671     3717777  B00F415LEU      4.0   \n",
       "\n",
       "                                             reviewText  \\\n",
       "508   This is an extreme disappointment. I purchased...   \n",
       "3197  I've had these speakers for about six weeks an...   \n",
       "2863  I'm a drummer and have been involved with musi...   \n",
       "4570  First I must thank Amazon for their exceptiona...   \n",
       "3671  Let me preface this review by saying for a lon...   \n",
       "\n",
       "                                                summary  Review_Length  \\\n",
       "508                                   25 Mile Range Max         3865.0   \n",
       "3197      Great hassle free 2.1 system at a great price         5279.0   \n",
       "2863                The Truth about these Headphones...         3110.0   \n",
       "4570  Leading hardware and BIOS design - you get wha...         2514.0   \n",
       "3671  Unexpectedly brilliant, at least for an iOS de...        16996.0   \n",
       "\n",
       "      sentiment sentiment_name  \n",
       "508           0       negative  \n",
       "3197          2       positive  \n",
       "2863          1        neutral  \n",
       "4570          2       positive  \n",
       "3671          2       positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"sentiment_name\"] = test_df['sentiment'].apply(lambda row: label_int2str(row))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare model to train (fine-tune) and initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 19204, 6026, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Tokenizing is a core task of nlp\"\n",
    "encoded_txt = tokenizer(text)\n",
    "print(encoded_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'token', '##izing', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encoded_txt.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] tokenizing is a core task of nlp [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_string(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(train_df['reviewText'].tolist(), padding='max_length', truncation=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = tokenizer(test_df['reviewText'].tolist(), padding='max_length', truncation=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2363,  ...,  2662,  1012,   102],\n",
       "        [  101,  1045,  1005,  ...,  2677,  2296,   102],\n",
       "        [  101,  1045,  2031,  ...,  3287,  2030,   102],\n",
       "        ...,\n",
       "        [  101,  1026,  1037,  ...,  1011,  1999,   102],\n",
       "        [  101,  1045,  2031,  ..., 20919,  3096,   102],\n",
       "        [  101,  4013,  2015,  ...,  1045,  1010,   102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up environment for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 3\n",
    "model = (DistilBertForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average=\"weighted\")\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gupta\\anaconda3\\envs\\nlp\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000\n"
     ]
    }
   ],
   "source": [
    "class AmazonReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Prepare labels for the datasets\n",
    "train_labels = train_df['sentiment'].tolist()\n",
    "test_labels = test_df['sentiment'].tolist()\n",
    "print(len(train_labels), len(test_labels))\n",
    "# Create custom datasets\n",
    "train_dataset = AmazonReviewDataset(inputs, train_labels)\n",
    "test_dataset = AmazonReviewDataset(inputs_test, test_labels)\n",
    "\n",
    "# Initialize the Trainer with the custom datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "logging_steps = len(train_dataset) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-amazon-electronics\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=50,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False,\n",
    "                                  log_level='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, train_dataset=train_dataset, eval_dataset=test_dataset, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f6ed34ccc84195b863d0016b0b3b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3982, 'learning_rate': 1.9600000000000002e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4021cd2133d640979d4e68debed8c222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4626332521438599, 'eval_accuracy': 0.617, 'eval_f1': 0.6315975017946878, 'eval_precision': 0.6713681759559413, 'eval_recall': 0.617, 'eval_runtime': 30.1211, 'eval_samples_per_second': 33.199, 'eval_steps_per_second': 4.15, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3264, 'learning_rate': 1.9200000000000003e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea270d05514748baa359075d3b820e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5764691829681396, 'eval_accuracy': 0.619, 'eval_f1': 0.6373812666360921, 'eval_precision': 0.6727402424802388, 'eval_recall': 0.619, 'eval_runtime': 31.4141, 'eval_samples_per_second': 31.833, 'eval_steps_per_second': 3.979, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3055, 'learning_rate': 1.88e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2179b41606ad4f539f12c8561eeab6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8460007905960083, 'eval_accuracy': 0.616, 'eval_f1': 0.6312552194142227, 'eval_precision': 0.6708085702345641, 'eval_recall': 0.616, 'eval_runtime': 32.1611, 'eval_samples_per_second': 31.093, 'eval_steps_per_second': 3.887, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2574, 'learning_rate': 1.8400000000000003e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d4a132e0624c16ab62d9721d01075c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9016982316970825, 'eval_accuracy': 0.593, 'eval_f1': 0.6168769702717073, 'eval_precision': 0.6737602355119636, 'eval_recall': 0.593, 'eval_runtime': 32.7357, 'eval_samples_per_second': 30.548, 'eval_steps_per_second': 3.818, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1709, 'learning_rate': 1.8e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bc0c9e41314ce1bea1a58873289321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.15547776222229, 'eval_accuracy': 0.643, 'eval_f1': 0.6532907006732249, 'eval_precision': 0.6697088409007014, 'eval_recall': 0.643, 'eval_runtime': 33.1385, 'eval_samples_per_second': 30.176, 'eval_steps_per_second': 3.772, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1478, 'learning_rate': 1.76e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baa38c5710b4ec7b5add40652c43422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4427366256713867, 'eval_accuracy': 0.621, 'eval_f1': 0.6333363773588253, 'eval_precision': 0.6647854160212228, 'eval_recall': 0.621, 'eval_runtime': 32.5871, 'eval_samples_per_second': 30.687, 'eval_steps_per_second': 3.836, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1031, 'learning_rate': 1.72e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5b39bd77f24e29b2bbb47b68bf385e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5097429752349854, 'eval_accuracy': 0.625, 'eval_f1': 0.6351535129071785, 'eval_precision': 0.6502620387289961, 'eval_recall': 0.625, 'eval_runtime': 33.0593, 'eval_samples_per_second': 30.249, 'eval_steps_per_second': 3.781, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0932, 'learning_rate': 1.6800000000000002e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c8993ae60e4c9cbabe182aa04a7c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8340303897857666, 'eval_accuracy': 0.622, 'eval_f1': 0.6318306730441606, 'eval_precision': 0.660472238806935, 'eval_recall': 0.622, 'eval_runtime': 33.1502, 'eval_samples_per_second': 30.166, 'eval_steps_per_second': 3.771, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0879, 'learning_rate': 1.64e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7f4f83532642839cbf33857980ef39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6741137504577637, 'eval_accuracy': 0.638, 'eval_f1': 0.648883790402236, 'eval_precision': 0.666556810767175, 'eval_recall': 0.638, 'eval_runtime': 32.677, 'eval_samples_per_second': 30.603, 'eval_steps_per_second': 3.825, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0676, 'learning_rate': 1.6000000000000003e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cef308ffbbd4f168048495ee089250a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8306806087493896, 'eval_accuracy': 0.61, 'eval_f1': 0.6288400734183189, 'eval_precision': 0.6755344504993335, 'eval_recall': 0.61, 'eval_runtime': 32.8567, 'eval_samples_per_second': 30.435, 'eval_steps_per_second': 3.804, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0562, 'learning_rate': 1.5600000000000003e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a090891491454884e1431420141e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.215977430343628, 'eval_accuracy': 0.606, 'eval_f1': 0.6122222116309702, 'eval_precision': 0.6571031207598371, 'eval_recall': 0.606, 'eval_runtime': 32.9457, 'eval_samples_per_second': 30.353, 'eval_steps_per_second': 3.794, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0606, 'learning_rate': 1.5200000000000002e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40a827c27834a18a8992ca254e38371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8721320629119873, 'eval_accuracy': 0.621, 'eval_f1': 0.6263199052493946, 'eval_precision': 0.635444845547604, 'eval_recall': 0.621, 'eval_runtime': 32.9336, 'eval_samples_per_second': 30.364, 'eval_steps_per_second': 3.796, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0368, 'learning_rate': 1.48e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b3d47791d44d279d91ceb7c8646cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1032378673553467, 'eval_accuracy': 0.642, 'eval_f1': 0.643064560436402, 'eval_precision': 0.6446973714244376, 'eval_recall': 0.642, 'eval_runtime': 29.7262, 'eval_samples_per_second': 33.64, 'eval_steps_per_second': 4.205, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0435, 'learning_rate': 1.4400000000000001e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61d1cfbf7eb43a9a12b862db67715e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3218026161193848, 'eval_accuracy': 0.641, 'eval_f1': 0.6431355158539942, 'eval_precision': 0.646062207566466, 'eval_recall': 0.641, 'eval_runtime': 29.6955, 'eval_samples_per_second': 33.675, 'eval_steps_per_second': 4.209, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0537, 'learning_rate': 1.4e-05, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29a459a6dd047a08a47c6c8a161202c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.448566436767578, 'eval_accuracy': 0.619, 'eval_f1': 0.6351881825115953, 'eval_precision': 0.6738412342215989, 'eval_recall': 0.619, 'eval_runtime': 29.7001, 'eval_samples_per_second': 33.67, 'eval_steps_per_second': 4.209, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0369, 'learning_rate': 1.3600000000000002e-05, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91deb3fd3a14ab8ad4235d65e2f497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4309418201446533, 'eval_accuracy': 0.629, 'eval_f1': 0.6400700131043127, 'eval_precision': 0.6584350377276356, 'eval_recall': 0.629, 'eval_runtime': 29.7232, 'eval_samples_per_second': 33.644, 'eval_steps_per_second': 4.205, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0276, 'learning_rate': 1.3200000000000002e-05, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf0ca7e48e445ed9b1714b293c61148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6500444412231445, 'eval_accuracy': 0.627, 'eval_f1': 0.6286091300457519, 'eval_precision': 0.6369256437529064, 'eval_recall': 0.627, 'eval_runtime': 30.0845, 'eval_samples_per_second': 33.24, 'eval_steps_per_second': 4.155, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0295, 'learning_rate': 1.2800000000000001e-05, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6ce1389ab94240aa37931d0032da61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.6480517387390137, 'eval_accuracy': 0.629, 'eval_f1': 0.6377082185388449, 'eval_precision': 0.6498827479338842, 'eval_recall': 0.629, 'eval_runtime': 29.7501, 'eval_samples_per_second': 33.613, 'eval_steps_per_second': 4.202, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0398, 'learning_rate': 1.2400000000000002e-05, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c78a30640b4e7ab2a02ad9525f1356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4565205574035645, 'eval_accuracy': 0.632, 'eval_f1': 0.6314385092193849, 'eval_precision': 0.6342584428279742, 'eval_recall': 0.632, 'eval_runtime': 29.9553, 'eval_samples_per_second': 33.383, 'eval_steps_per_second': 4.173, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0424, 'learning_rate': 1.2e-05, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de0fe7bc0a647bb9686839a5dd6f4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1799185276031494, 'eval_accuracy': 0.636, 'eval_f1': 0.6437153896484895, 'eval_precision': 0.6549508888982729, 'eval_recall': 0.636, 'eval_runtime': 30.0126, 'eval_samples_per_second': 33.319, 'eval_steps_per_second': 4.165, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0201, 'learning_rate': 1.16e-05, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055768d4e62d4e3d86f5ffb953642ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.693693161010742, 'eval_accuracy': 0.638, 'eval_f1': 0.6506514623579674, 'eval_precision': 0.6737424754685704, 'eval_recall': 0.638, 'eval_runtime': 29.907, 'eval_samples_per_second': 33.437, 'eval_steps_per_second': 4.18, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'learning_rate': 1.1200000000000001e-05, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125b9aa02782441285790259498427b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.007307052612305, 'eval_accuracy': 0.611, 'eval_f1': 0.6210966380158538, 'eval_precision': 0.6491707944514502, 'eval_recall': 0.611, 'eval_runtime': 29.9806, 'eval_samples_per_second': 33.355, 'eval_steps_per_second': 4.169, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0289, 'learning_rate': 1.0800000000000002e-05, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80c2f618a2c476e9ca986d75e1e32f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.744584321975708, 'eval_accuracy': 0.64, 'eval_f1': 0.6422619872509179, 'eval_precision': 0.6485213556583682, 'eval_recall': 0.64, 'eval_runtime': 29.2917, 'eval_samples_per_second': 34.139, 'eval_steps_per_second': 4.267, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0166, 'learning_rate': 1.04e-05, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f1f20bec744c8aa10824b6dffe418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.779660224914551, 'eval_accuracy': 0.632, 'eval_f1': 0.6373857227537085, 'eval_precision': 0.6474307377016049, 'eval_recall': 0.632, 'eval_runtime': 28.9822, 'eval_samples_per_second': 34.504, 'eval_steps_per_second': 4.313, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0093, 'learning_rate': 1e-05, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8db11bbd44a4377a13404a0831ac1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.154170989990234, 'eval_accuracy': 0.604, 'eval_f1': 0.6211254823111628, 'eval_precision': 0.6535739780658026, 'eval_recall': 0.604, 'eval_runtime': 29.6045, 'eval_samples_per_second': 33.779, 'eval_steps_per_second': 4.222, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0212, 'learning_rate': 9.600000000000001e-06, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce726be34f8f4a4396ba2d26700615fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.00478982925415, 'eval_accuracy': 0.612, 'eval_f1': 0.625738101522423, 'eval_precision': 0.6488018081755794, 'eval_recall': 0.612, 'eval_runtime': 29.9811, 'eval_samples_per_second': 33.354, 'eval_steps_per_second': 4.169, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0265, 'learning_rate': 9.200000000000002e-06, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b75827f4614798b9e2f0efeb66fd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.780691385269165, 'eval_accuracy': 0.641, 'eval_f1': 0.6368598964472246, 'eval_precision': 0.6334208594432608, 'eval_recall': 0.641, 'eval_runtime': 29.8424, 'eval_samples_per_second': 33.509, 'eval_steps_per_second': 4.189, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0229, 'learning_rate': 8.8e-06, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f898881a6b8a41588258321dfb230809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.97573184967041, 'eval_accuracy': 0.608, 'eval_f1': 0.6168308655500694, 'eval_precision': 0.6306693331166118, 'eval_recall': 0.608, 'eval_runtime': 29.4799, 'eval_samples_per_second': 33.921, 'eval_steps_per_second': 4.24, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0156, 'learning_rate': 8.400000000000001e-06, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17264eaf40c44cfeadf26d64afbf99f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.966329336166382, 'eval_accuracy': 0.629, 'eval_f1': 0.6361918105194129, 'eval_precision': 0.6487169473240183, 'eval_recall': 0.629, 'eval_runtime': 29.2453, 'eval_samples_per_second': 34.194, 'eval_steps_per_second': 4.274, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0156, 'learning_rate': 8.000000000000001e-06, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ea4263bc44426cbec7ecfd3c23119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9693784713745117, 'eval_accuracy': 0.618, 'eval_f1': 0.6258237336662977, 'eval_precision': 0.6362472390995676, 'eval_recall': 0.618, 'eval_runtime': 29.0571, 'eval_samples_per_second': 34.415, 'eval_steps_per_second': 4.302, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.01, 'learning_rate': 7.600000000000001e-06, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23113e7874174b6e869a2247f1fd262d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9667704105377197, 'eval_accuracy': 0.619, 'eval_f1': 0.6283217952909028, 'eval_precision': 0.6440692681464991, 'eval_recall': 0.619, 'eval_runtime': 29.0199, 'eval_samples_per_second': 34.459, 'eval_steps_per_second': 4.307, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0067, 'learning_rate': 7.2000000000000005e-06, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce2a1adc8224df99c8ebfc32db4cfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.2160820960998535, 'eval_accuracy': 0.602, 'eval_f1': 0.6172976200394298, 'eval_precision': 0.6514270625361128, 'eval_recall': 0.602, 'eval_runtime': 28.9307, 'eval_samples_per_second': 34.565, 'eval_steps_per_second': 4.321, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0142, 'learning_rate': 6.800000000000001e-06, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8d4d9bd8b6419f95b94ba96e578fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.118749141693115, 'eval_accuracy': 0.616, 'eval_f1': 0.6249499951379801, 'eval_precision': 0.6431493203924288, 'eval_recall': 0.616, 'eval_runtime': 29.0248, 'eval_samples_per_second': 34.453, 'eval_steps_per_second': 4.307, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.01, 'learning_rate': 6.4000000000000006e-06, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788b5505977b4b418d67c5094f8e01b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.207690238952637, 'eval_accuracy': 0.625, 'eval_f1': 0.6311383592267248, 'eval_precision': 0.6422457946785023, 'eval_recall': 0.625, 'eval_runtime': 29.3717, 'eval_samples_per_second': 34.046, 'eval_steps_per_second': 4.256, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0164, 'learning_rate': 6e-06, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbe745261c848dfb96a0e9540b0f665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.460136890411377, 'eval_accuracy': 0.603, 'eval_f1': 0.6219259776200982, 'eval_precision': 0.6648404389310758, 'eval_recall': 0.603, 'eval_runtime': 30.7215, 'eval_samples_per_second': 32.55, 'eval_steps_per_second': 4.069, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0083, 'learning_rate': 5.600000000000001e-06, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90c90ed332d4ed3aa9c1025a6634bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.1100006103515625, 'eval_accuracy': 0.634, 'eval_f1': 0.6387990808183449, 'eval_precision': 0.6504818574047188, 'eval_recall': 0.634, 'eval_runtime': 31.735, 'eval_samples_per_second': 31.511, 'eval_steps_per_second': 3.939, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0102, 'learning_rate': 5.2e-06, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4d5320a5404a4dbb7c27db978bc796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.9707627296447754, 'eval_accuracy': 0.645, 'eval_f1': 0.6437075415065028, 'eval_precision': 0.642894778296208, 'eval_recall': 0.645, 'eval_runtime': 31.925, 'eval_samples_per_second': 31.323, 'eval_steps_per_second': 3.915, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0049, 'learning_rate': 4.800000000000001e-06, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d868da954dc49c09d06a7f7071c7a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.227459907531738, 'eval_accuracy': 0.63, 'eval_f1': 0.6360769976286215, 'eval_precision': 0.6500855484940591, 'eval_recall': 0.63, 'eval_runtime': 32.4117, 'eval_samples_per_second': 30.853, 'eval_steps_per_second': 3.857, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'learning_rate': 4.4e-06, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1d692b320043a1888cb4e86ad27bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.187099456787109, 'eval_accuracy': 0.624, 'eval_f1': 0.6246667786754034, 'eval_precision': 0.6311296867397732, 'eval_recall': 0.624, 'eval_runtime': 31.8658, 'eval_samples_per_second': 31.382, 'eval_steps_per_second': 3.923, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0042, 'learning_rate': 4.000000000000001e-06, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41ef6117b9b4490b6da1591fef04973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.139225959777832, 'eval_accuracy': 0.636, 'eval_f1': 0.639268413548825, 'eval_precision': 0.6442332940695232, 'eval_recall': 0.636, 'eval_runtime': 32.4744, 'eval_samples_per_second': 30.794, 'eval_steps_per_second': 3.849, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0052, 'learning_rate': 3.6000000000000003e-06, 'epoch': 41.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18c3c09b90b440cb057c87359f7e817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.258829593658447, 'eval_accuracy': 0.626, 'eval_f1': 0.6353226407491533, 'eval_precision': 0.6504639586109304, 'eval_recall': 0.626, 'eval_runtime': 31.5439, 'eval_samples_per_second': 31.702, 'eval_steps_per_second': 3.963, 'epoch': 41.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0016, 'learning_rate': 3.2000000000000003e-06, 'epoch': 42.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc5167a2d73448cb9c46b081dd4c457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.163698196411133, 'eval_accuracy': 0.636, 'eval_f1': 0.6359938573444266, 'eval_precision': 0.6361604876683661, 'eval_recall': 0.636, 'eval_runtime': 31.9469, 'eval_samples_per_second': 31.302, 'eval_steps_per_second': 3.913, 'epoch': 42.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0127, 'learning_rate': 2.8000000000000003e-06, 'epoch': 43.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c3cbb4f33f496085109382318c8f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.434605121612549, 'eval_accuracy': 0.611, 'eval_f1': 0.6270144630858698, 'eval_precision': 0.6570942857142856, 'eval_recall': 0.611, 'eval_runtime': 32.741, 'eval_samples_per_second': 30.543, 'eval_steps_per_second': 3.818, 'epoch': 43.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0027, 'learning_rate': 2.4000000000000003e-06, 'epoch': 44.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c92d52044c745feb47fac42ee006c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.259355545043945, 'eval_accuracy': 0.632, 'eval_f1': 0.6381932265384621, 'eval_precision': 0.6479305584739029, 'eval_recall': 0.632, 'eval_runtime': 32.1187, 'eval_samples_per_second': 31.135, 'eval_steps_per_second': 3.892, 'epoch': 44.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.0000000000000003e-06, 'epoch': 45.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfda547e5a2454483bbbaf2a69f9aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.3002705574035645, 'eval_accuracy': 0.624, 'eval_f1': 0.6354257253578751, 'eval_precision': 0.6534538099199805, 'eval_recall': 0.624, 'eval_runtime': 31.1505, 'eval_samples_per_second': 32.102, 'eval_steps_per_second': 4.013, 'epoch': 45.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0032, 'learning_rate': 1.6000000000000001e-06, 'epoch': 46.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d149972503450eb5b11a7cfc5f7c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.298238277435303, 'eval_accuracy': 0.629, 'eval_f1': 0.638007682234832, 'eval_precision': 0.651053632997063, 'eval_recall': 0.629, 'eval_runtime': 30.7433, 'eval_samples_per_second': 32.527, 'eval_steps_per_second': 4.066, 'epoch': 46.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'learning_rate': 1.2000000000000002e-06, 'epoch': 47.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d156fbc083646eea7061ca98abfa0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.5305399894714355, 'eval_accuracy': 0.616, 'eval_f1': 0.6310958385043507, 'eval_precision': 0.6590584590690208, 'eval_recall': 0.616, 'eval_runtime': 30.771, 'eval_samples_per_second': 32.498, 'eval_steps_per_second': 4.062, 'epoch': 47.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 8.000000000000001e-07, 'epoch': 48.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120ed5b3330147efa3abee3996f475d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.520141124725342, 'eval_accuracy': 0.614, 'eval_f1': 0.6279501850694928, 'eval_precision': 0.6524458102919871, 'eval_recall': 0.614, 'eval_runtime': 30.3717, 'eval_samples_per_second': 32.925, 'eval_steps_per_second': 4.116, 'epoch': 48.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0032, 'learning_rate': 4.0000000000000003e-07, 'epoch': 49.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7931108354be4da68351b9f73959e230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.369132995605469, 'eval_accuracy': 0.628, 'eval_f1': 0.6378846772248886, 'eval_precision': 0.6534233755467613, 'eval_recall': 0.628, 'eval_runtime': 31.0306, 'eval_samples_per_second': 32.226, 'eval_steps_per_second': 4.028, 'epoch': 49.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'learning_rate': 0.0, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe650169bd5402b84a994392b057bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.344789981842041, 'eval_accuracy': 0.629, 'eval_f1': 0.635597061442786, 'eval_precision': 0.64627856832655, 'eval_recall': 0.629, 'eval_runtime': 32.5168, 'eval_samples_per_second': 30.753, 'eval_steps_per_second': 3.844, 'epoch': 50.0}\n",
      "{'train_runtime': 17014.2108, 'train_samples_per_second': 11.755, 'train_steps_per_second': 1.469, 'train_loss': 0.05411074604809284, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25000, training_loss=0.05411074604809284, metrics={'train_runtime': 17014.2108, 'train_samples_per_second': 11.755, 'train_steps_per_second': 1.469, 'train_loss': 0.05411074604809284, 'epoch': 50.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_18232\\3509680498.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8194c14c9144d99994d54982f4ea3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_output = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 4.344789981842041,\n",
       " 'test_accuracy': 0.629,\n",
       " 'test_f1': 0.635597061442786,\n",
       " 'test_precision': 0.64627856832655,\n",
       " 'test_recall': 0.629,\n",
       " 'test_runtime': 27.5084,\n",
       " 'test_samples_per_second': 36.352,\n",
       " 'test_steps_per_second': 4.544}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert-base-uncased-finetuned-amazon-electronics'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "saved_tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_pipeline = pipeline('sentiment-analysis', model=saved_model, tokenizer=saved_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I recently upgraded to the OnePlus Nord CE 3 Lite 5G in Pastel Lime, and I've been thoroughly impressed with its performance and features. Here's what I love about it:\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "1. **Affordable 5G:** The inclusion of 5G capabilities in a phone at this price point is a huge plus. Streaming and downloading content is lightning-fast, and I'm future-proofed for upcoming advancements in connectivity.\n",
    "\n",
    "2. **Sleek Design:** The Pastel Lime color is unique and adds a refreshing touch to the device. The slim profile and lightweight build make it comfortable to hold and use for extended periods.\n",
    "\n",
    "3. **Smooth Performance:** With 8GB of RAM, multitasking is a breeze. The phone handles various apps and tasks simultaneously without any lag or slowdowns.\n",
    "\n",
    "4. **Ample Storage:** The 128GB storage provides enough room for all my apps, photos, and videos. Plus, the option to expand storage via microSD card is a thoughtful addition.\n",
    "\n",
    "5. **Impressive Display:** The AMOLED display offers vibrant colors and deep blacks, enhancing my media consumption experience. The Full HD+ resolution ensures crisp visuals, whether I'm watching videos or browsing the web.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "1. **Average Camera Performance:** While the camera setup is decent, it doesn't quite match the quality of flagship devices. Photos in well-lit conditions turn out great, but low-light performance could be improved.\n",
    "\n",
    "2. **Plastic Back:** While the plastic back keeps the device lightweight, it may not feel as premium as glass-backed phones. A good quality case helps mitigate this, though.\n",
    "\n",
    "3. **Battery Life:** The battery life is good, but not exceptional. It easily lasts me through a day of moderate use, but I/'d appreciate a bit more juice for heavy usage days.\n",
    "\n",
    "In conclusion, the OnePlus Nord CE 3 Lite 5G offers a compelling package of features at an affordable price. It/'s a great option for users who want to experience 5G connectivity without breaking the bank. The design, performance, and display quality are its standout features, making it an excellent value for money. While there are a few areas for improvement, the overall experience this phone provides is truly remarkable.\n",
    ".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\anaconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# results = senti_pipeline(\"I am going to the toilet to poop and it is bad\")\n",
    "results = senti_pipeline(text, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 1.8133121670871333e-07},\n",
       "  {'label': 'LABEL_1', 'score': 7.667644581488275e-07},\n",
       "  {'label': 'LABEL_2', 'score': 0.9999990463256836}]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame(results[0])\n",
    "labels = preds_df['label'].tolist()\n",
    "plt.bar(labels, 100*preds_df['score'], color='C0')\n",
    "plt.ylabel('Sentiment Score (%)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
