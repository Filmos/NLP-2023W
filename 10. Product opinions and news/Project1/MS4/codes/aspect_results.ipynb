{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoszrozek/Documents/Studies/s02/NLP/Project 1/NLP-BAMK-project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "/bin/sh: line 1: nvidia-smi: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA GPU found in your device\n",
      "[2024-01-02 22:48:38] (2.3.4) \u001b[31mPyABSA(2.3.4): If your code crashes on Colab, please use the GPU runtime. Then run \"pip install pyabsa[dev] -U\" and restart the kernel.\n",
      "Or if it does not work, you can use v1.x versions, e.g., pip install pyabsa<2.0 -U\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WARNING: When you fails to load a checkpoint, e.g., Unexpected key(s),\n",
      "Try to downgrade transformers<=4.29.0.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/multiprocessing/pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n"
     ]
    }
   ],
   "source": [
    "from pysent import AspectAnotator\n",
    "import pysent.aspect_annotators.extractors as extractors\n",
    "import pysent.aspect_annotators.classifiers as classifiers\n",
    "import pysent.aspect_annotators.extrassifiers as extrassifiers\n",
    "from pysent.data_structures import concat_results\n",
    "from pysent.transforms import *\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and turn into appropriate formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptops = pd.read_csv(\"../data/Laptop_Train_v2.csv\").sort_values(by=['id'])\n",
    "laptops.Sentence = laptops.Sentence.map(lambda x: x.replace(\"'\", \"\").replace('\"', ''))\n",
    "restaurants = pd.read_csv(\"../data/Restaurants_Train_v2.csv\").sort_values(by=['id'])\n",
    "restaurants.Sentence = restaurants.Sentence.map(lambda x: x.replace(\"'\", \"\").replace('\"', ''))\n",
    "laptops_sentiment = transform_aspects(laptops, \"id\", \"Sentence\", \"Aspect Term\", \"polarity\")\n",
    "restaurants_sentiment = transform_aspects(restaurants, \"id\", \"Sentence\", \"Aspect Term\", \"polarity\")\n",
    "idxs = random.sample(range(len(laptops_sentiment)), 30)\n",
    "laptops_sentiment_small = [laptops_sentiment[i] for i in idxs]\n",
    "restaurants_sentiment_small = [restaurants_sentiment[i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize instances for every annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-02 22:48:49] (2.3.4) Please specify the task code, e.g. from pyabsa import TaskCodeOption\n",
      "[2024-01-02 22:48:50] (2.3.4) \u001b[32mDownloading checkpoint:multilingual \u001b[0m\n",
      "[2024-01-02 22:48:50] (2.3.4) \u001b[31mNotice: The pretrained model are used for testing, it is recommended to train the model on your own custom datasets\u001b[0m\n",
      "[2024-01-02 22:48:50] (2.3.4) Checkpoint already downloaded, skip\n",
      "[2024-01-02 22:48:50] (2.3.4) Load aspect extractor from checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT\n",
      "[2024-01-02 22:48:50] (2.3.4) config: checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT/fast_lcf_atepc.config\n",
      "[2024-01-02 22:48:50] (2.3.4) state_dict: checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT/fast_lcf_atepc.state_dict\n",
      "[2024-01-02 22:48:50] (2.3.4) model: None\n",
      "[2024-01-02 22:48:50] (2.3.4) tokenizer: checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT/fast_lcf_atepc.tokenizer\n",
      "[2024-01-02 22:48:50] (2.3.4) Set Model Device: cpu\n",
      "[2024-01-02 22:48:50] (2.3.4) Device Name: Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoszrozek/Documents/Studies/s02/NLP/Project 1/NLP-BAMK-project/.venv/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n"
     ]
    }
   ],
   "source": [
    "chat_ext = extractors.ChatGPTExtractor(api_key=\"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\")\n",
    "pyabsa_ext = extractors.PyabsaExtractor()\n",
    "spacy_ext = extractors.SpacyExtractor()\n",
    "nltk_ext = extractors.NltkExtractor()\n",
    "extractors_ = [chat_ext, pyabsa_ext, spacy_ext]\n",
    "extractors_ = [pyabsa_ext, spacy_ext, nltk_ext]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_cl = classifiers.FlairClassifier()\n",
    "senti_cl = classifiers.SentiClassifier(ss_jar_path='/home/bartoszrozek/Downloads/pysenti/PySentiStrength-1.0.1/pysenti/original/SentiStrength.jar',\n",
    "                                ss_lang_path='/home/bartoszrozek/Downloads/pysenti/PySentiStrength-1.0.1/pysenti/original/data')\n",
    "classifiers_ = [flair_cl, senti_cl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create combinations of extractors and classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = list(list(tup) for tup in itertools.product(extractors_, classifiers_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-02 22:49:14] (2.3.4) Please specify the task code, e.g. from pyabsa import TaskCodeOption\n",
      "[2024-01-02 22:49:14] (2.3.4) \u001b[32mDownloading checkpoint:multilingual \u001b[0m\n",
      "[2024-01-02 22:49:14] (2.3.4) \u001b[31mNotice: The pretrained model are used for testing, it is recommended to train the model on your own custom datasets\u001b[0m\n",
      "[2024-01-02 22:49:14] (2.3.4) Checkpoint already downloaded, skip\n",
      "[2024-01-02 22:49:14] (2.3.4) Load aspect extractor from checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT\n",
      "[2024-01-02 22:49:14] (2.3.4) config: checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT/fast_lcf_atepc.config\n",
      "[2024-01-02 22:49:14] (2.3.4) state_dict: checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT/fast_lcf_atepc.state_dict\n",
      "[2024-01-02 22:49:14] (2.3.4) model: None\n",
      "[2024-01-02 22:49:14] (2.3.4) tokenizer: checkpoints/ATEPC_MULTILINGUAL_CHECKPOINT/fast_lcf_atepc.tokenizer\n",
      "[2024-01-02 22:49:15] (2.3.4) Set Model Device: cpu\n",
      "[2024-01-02 22:49:15] (2.3.4) Device Name: Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoszrozek/Documents/Studies/s02/NLP/Project 1/NLP-BAMK-project/.venv/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n"
     ]
    }
   ],
   "source": [
    "chat_full = extrassifiers.ChatGPTExtrassifier(api_key=\"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\")\n",
    "pyabsa_full = extrassifiers.PyabsaExtrassifier()\n",
    "full_tools = [[chat_full], [pyabsa_full]]\n",
    "full_tools = [[pyabsa_full]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = pipelines + full_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test every annotator on the gold standard dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to limitations of the chat gpt free tier account we needed to reduce number of texts for methods based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def check_if_gpt(pipeline):\n",
    "    types = [str(type(x)) for x in pipeline]\n",
    "    regexp = re.compile(\"GPT\")\n",
    "    gpts = [bool(regexp.search(type)) for type in types]\n",
    "    is_gpt = bool(np.sum(gpts) > 0)\n",
    "    return is_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 1488/1488 [00:00<00:00, 1799.96it/s]\n",
      "extracting aspect terms: 100%|██████████| 47/47 [06:18<00:00,  8.06s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 2426/2426 [00:02<00:00, 850.84it/s]\n",
      "/home/bartoszrozek/Documents/Studies/s02/NLP/Project 1/NLP-BAMK-project/.venv/lib/python3.11/site-packages/pyabsa/tasks/AspectTermExtraction/prediction/aspect_extractor.py:566: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "classifying aspect sentiments: 100%|██████████| 76/76 [11:06<00:00,  8.76s/it]\n",
      "preparing ate inference dataloader: 100%|██████████| 1488/1488 [00:00<00:00, 1561.55it/s]\n",
      "extracting aspect terms: 100%|██████████| 47/47 [05:17<00:00,  6.75s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 2426/2426 [00:02<00:00, 1086.22it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 76/76 [05:31<00:00,  4.36s/it]\n",
      "preparing ate inference dataloader: 100%|██████████| 1488/1488 [00:00<00:00, 1995.82it/s]\n",
      "extracting aspect terms: 100%|██████████| 47/47 [02:40<00:00,  3.41s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 2426/2426 [00:01<00:00, 1279.12it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 76/76 [10:30<00:00,  8.30s/it] \n"
     ]
    }
   ],
   "source": [
    "results_laptops = []\n",
    "for pipeline in pipelines:\n",
    "    annotator = AspectAnotator(pipeline)\n",
    "    if check_if_gpt(pipeline):\n",
    "        result = annotator.test_annotator(laptops_sentiment_small)\n",
    "    else:\n",
    "        pass\n",
    "        result = annotator.test_annotator(laptops_sentiment)\n",
    "    results_laptops.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing ate inference dataloader: 100%|██████████| 2021/2021 [00:02<00:00, 767.64it/s]\n",
      "extracting aspect terms: 100%|██████████| 64/64 [03:45<00:00,  3.52s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 3766/3766 [00:06<00:00, 580.11it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 118/118 [07:07<00:00,  3.62s/it]\n",
      "preparing ate inference dataloader: 100%|██████████| 2021/2021 [00:02<00:00, 818.46it/s]\n",
      "extracting aspect terms: 100%|██████████| 64/64 [03:49<00:00,  3.59s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 3766/3766 [00:07<00:00, 526.82it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 118/118 [07:33<00:00,  3.85s/it]\n",
      "preparing ate inference dataloader: 100%|██████████| 2021/2021 [00:02<00:00, 898.85it/s]\n",
      "extracting aspect terms: 100%|██████████| 64/64 [03:54<00:00,  3.66s/it]\n",
      "preparing apc inference dataloader: 100%|██████████| 3766/3766 [00:06<00:00, 555.70it/s]\n",
      "classifying aspect sentiments: 100%|██████████| 118/118 [07:33<00:00,  3.84s/it]\n"
     ]
    }
   ],
   "source": [
    "results_restaurants = []\n",
    "for pipeline in pipelines:\n",
    "    annotator = AspectAnotator(pipeline)\n",
    "    if check_if_gpt(pipeline):\n",
    "        result = annotator.test_annotator(restaurants_sentiment_small)\n",
    "    else:\n",
    "        result = annotator.test_annotator(restaurants_sentiment)\n",
    "    results_restaurants.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Value</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>1303</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>737</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial</td>\n",
       "      <td>118</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>200</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spurious</td>\n",
       "      <td>268</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>2426</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.772465</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.794741</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.783445</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Statistic               Value                               Name\n",
       "0     correct                1303  PyabsaExtractor + FlairClassifier\n",
       "1   incorrect                 737  PyabsaExtractor + FlairClassifier\n",
       "2     partial                 118  PyabsaExtractor + FlairClassifier\n",
       "3     missing                 200  PyabsaExtractor + FlairClassifier\n",
       "4    spurious                 268  PyabsaExtractor + FlairClassifier\n",
       "..        ...                 ...                                ...\n",
       "6      actual                2426                 PyabsaExtrassifier\n",
       "7   precision            0.772465                 PyabsaExtrassifier\n",
       "8      recall            0.794741                 PyabsaExtrassifier\n",
       "9          f1            0.783445                 PyabsaExtrassifier\n",
       "10       name  PyabsaExtrassifier                 PyabsaExtrassifier\n",
       "\n",
       "[77 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_laptops_df = concat_results(results_laptops).drop_duplicates()\n",
    "results_laptops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistic</th>\n",
       "      <th>Value</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>2156</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1120</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial</td>\n",
       "      <td>221</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>196</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spurious</td>\n",
       "      <td>269</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>3693</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>3766</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.572491</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.583807</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.578094</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "      <td>PyabsaExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>2010</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>1253</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial</td>\n",
       "      <td>234</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>196</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spurious</td>\n",
       "      <td>269</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>3693</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>3766</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.533723</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.544273</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.538946</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "      <td>PyabsaExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>1019</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>604</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial</td>\n",
       "      <td>339</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>1731</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spurious</td>\n",
       "      <td>962</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>3693</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>2924</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.348495</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.275927</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.307995</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "      <td>SpacyExtractor + FlairClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>940</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>678</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial</td>\n",
       "      <td>344</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>1731</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spurious</td>\n",
       "      <td>962</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>3693</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>2924</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.321477</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.254536</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.284117</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "      <td>SpacyExtractor + SentiClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>correct</td>\n",
       "      <td>2898</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incorrect</td>\n",
       "      <td>301</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial</td>\n",
       "      <td>298</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>196</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spurious</td>\n",
       "      <td>269</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>possible</td>\n",
       "      <td>3693</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>actual</td>\n",
       "      <td>3766</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.769517</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.784728</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.777048</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>name</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "      <td>PyabsaExtrassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Statistic                              Value  \\\n",
       "0     correct                               2156   \n",
       "1   incorrect                               1120   \n",
       "2     partial                                221   \n",
       "3     missing                                196   \n",
       "4    spurious                                269   \n",
       "5    possible                               3693   \n",
       "6      actual                               3766   \n",
       "7   precision                           0.572491   \n",
       "8      recall                           0.583807   \n",
       "9          f1                           0.578094   \n",
       "10       name  PyabsaExtractor + FlairClassifier   \n",
       "0     correct                               2010   \n",
       "1   incorrect                               1253   \n",
       "2     partial                                234   \n",
       "3     missing                                196   \n",
       "4    spurious                                269   \n",
       "5    possible                               3693   \n",
       "6      actual                               3766   \n",
       "7   precision                           0.533723   \n",
       "8      recall                           0.544273   \n",
       "9          f1                           0.538946   \n",
       "10       name  PyabsaExtractor + SentiClassifier   \n",
       "0     correct                               1019   \n",
       "1   incorrect                                604   \n",
       "2     partial                                339   \n",
       "3     missing                               1731   \n",
       "4    spurious                                962   \n",
       "5    possible                               3693   \n",
       "6      actual                               2924   \n",
       "7   precision                           0.348495   \n",
       "8      recall                           0.275927   \n",
       "9          f1                           0.307995   \n",
       "10       name   SpacyExtractor + FlairClassifier   \n",
       "0     correct                                940   \n",
       "1   incorrect                                678   \n",
       "2     partial                                344   \n",
       "3     missing                               1731   \n",
       "4    spurious                                962   \n",
       "5    possible                               3693   \n",
       "6      actual                               2924   \n",
       "7   precision                           0.321477   \n",
       "8      recall                           0.254536   \n",
       "9          f1                           0.284117   \n",
       "10       name   SpacyExtractor + SentiClassifier   \n",
       "0     correct                               2898   \n",
       "1   incorrect                                301   \n",
       "2     partial                                298   \n",
       "3     missing                                196   \n",
       "4    spurious                                269   \n",
       "5    possible                               3693   \n",
       "6      actual                               3766   \n",
       "7   precision                           0.769517   \n",
       "8      recall                           0.784728   \n",
       "9          f1                           0.777048   \n",
       "10       name                 PyabsaExtrassifier   \n",
       "\n",
       "                                 Name  \n",
       "0   PyabsaExtractor + FlairClassifier  \n",
       "1   PyabsaExtractor + FlairClassifier  \n",
       "2   PyabsaExtractor + FlairClassifier  \n",
       "3   PyabsaExtractor + FlairClassifier  \n",
       "4   PyabsaExtractor + FlairClassifier  \n",
       "5   PyabsaExtractor + FlairClassifier  \n",
       "6   PyabsaExtractor + FlairClassifier  \n",
       "7   PyabsaExtractor + FlairClassifier  \n",
       "8   PyabsaExtractor + FlairClassifier  \n",
       "9   PyabsaExtractor + FlairClassifier  \n",
       "10  PyabsaExtractor + FlairClassifier  \n",
       "0   PyabsaExtractor + SentiClassifier  \n",
       "1   PyabsaExtractor + SentiClassifier  \n",
       "2   PyabsaExtractor + SentiClassifier  \n",
       "3   PyabsaExtractor + SentiClassifier  \n",
       "4   PyabsaExtractor + SentiClassifier  \n",
       "5   PyabsaExtractor + SentiClassifier  \n",
       "6   PyabsaExtractor + SentiClassifier  \n",
       "7   PyabsaExtractor + SentiClassifier  \n",
       "8   PyabsaExtractor + SentiClassifier  \n",
       "9   PyabsaExtractor + SentiClassifier  \n",
       "10  PyabsaExtractor + SentiClassifier  \n",
       "0    SpacyExtractor + FlairClassifier  \n",
       "1    SpacyExtractor + FlairClassifier  \n",
       "2    SpacyExtractor + FlairClassifier  \n",
       "3    SpacyExtractor + FlairClassifier  \n",
       "4    SpacyExtractor + FlairClassifier  \n",
       "5    SpacyExtractor + FlairClassifier  \n",
       "6    SpacyExtractor + FlairClassifier  \n",
       "7    SpacyExtractor + FlairClassifier  \n",
       "8    SpacyExtractor + FlairClassifier  \n",
       "9    SpacyExtractor + FlairClassifier  \n",
       "10   SpacyExtractor + FlairClassifier  \n",
       "0    SpacyExtractor + SentiClassifier  \n",
       "1    SpacyExtractor + SentiClassifier  \n",
       "2    SpacyExtractor + SentiClassifier  \n",
       "3    SpacyExtractor + SentiClassifier  \n",
       "4    SpacyExtractor + SentiClassifier  \n",
       "5    SpacyExtractor + SentiClassifier  \n",
       "6    SpacyExtractor + SentiClassifier  \n",
       "7    SpacyExtractor + SentiClassifier  \n",
       "8    SpacyExtractor + SentiClassifier  \n",
       "9    SpacyExtractor + SentiClassifier  \n",
       "10   SpacyExtractor + SentiClassifier  \n",
       "0                  PyabsaExtrassifier  \n",
       "1                  PyabsaExtrassifier  \n",
       "2                  PyabsaExtrassifier  \n",
       "3                  PyabsaExtrassifier  \n",
       "4                  PyabsaExtrassifier  \n",
       "5                  PyabsaExtrassifier  \n",
       "6                  PyabsaExtrassifier  \n",
       "7                  PyabsaExtrassifier  \n",
       "8                  PyabsaExtrassifier  \n",
       "9                  PyabsaExtrassifier  \n",
       "10                 PyabsaExtrassifier  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_restaurants_df = concat_results(results_restaurants).drop_duplicates()\n",
    "results_restaurants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_laptops_df.to_csv(\"results/results_laptops_new_spacy.csv\")\n",
    "results_restaurants_df.to_csv(\"results/results_restaurants_new_spacy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
