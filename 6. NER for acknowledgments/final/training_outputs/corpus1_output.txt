2023-12-06 21:27:46,755 SequenceTagger predicts: Dictionary with 25 tags: O, S-Funding Agency, B-Funding Agency, E-Funding Agency, I-Funding Agency, S-Grant Number, B-Grant Number, E-Grant Number, I-Grant Number, S-Person, B-Person, E-Person, I-Person, S-Corporation, B-Corporation, E-Corporation, I-Corporation, S-University, B-University, E-University, I-University, S-Miscellaneous, B-Miscellaneous, E-Miscellaneous, I-Miscellaneous
2023-12-06 21:27:47,044 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,046 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)
  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2023-12-06 21:27:47,046 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,048 Corpus: 29 train + 10 dev + 10 test sentences
2023-12-06 21:27:47,048 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,050 Train:  29 sentences
2023-12-06 21:27:47,050         (train_with_dev=False, train_with_test=False)
2023-12-06 21:27:47,051 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,052 Training Params:
2023-12-06 21:27:47,053  - learning_rate: "0.1" 
2023-12-06 21:27:47,054  - mini_batch_size: "32"
2023-12-06 21:27:47,055  - max_epochs: "100"
2023-12-06 21:27:47,055  - shuffle: "True"
2023-12-06 21:27:47,056 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,057 Plugins:
2023-12-06 21:27:47,057  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'
2023-12-06 21:27:47,058 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,059 Final evaluation on model from best epoch (best-model.pt)
2023-12-06 21:27:47,062  - metric: "('micro avg', 'f1-score')"
2023-12-06 21:27:47,063 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,064 Computation:
2023-12-06 21:27:47,065  - compute on device: cpu
2023-12-06 21:27:47,066  - embedding storage: cpu
2023-12-06 21:27:47,068 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,068 Model training base path: "resources/taggers/ner"
2023-12-06 21:27:47,069 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:47,070 ----------------------------------------------------------------------------------------------------
/opt/conda/lib/python3.10/site-packages/flair/trainers/trainer.py:84: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.
  warnings.warn(
2023-12-06 21:27:53,103 epoch 1 - iter 1/1 - loss 3.76559882 - time (sec): 6.03 - samples/sec: 133.12 - lr: 0.100000 - momentum: 0.000000
2023-12-06 21:27:53,105 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:53,106 EPOCH 1 done: loss 3.7656 - lr: 0.100000
100%|██████████| 1/1 [00:00<00:00,  1.05it/s]
2023-12-06 21:27:54,075 DEV : loss 3.27634334564209 - f1-score (micro avg)  0.0308
2023-12-06 21:27:54,078  - 0 epochs without improvement
2023-12-06 21:27:54,079 saving best model

2023-12-06 21:27:55,040 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:55,859 epoch 2 - iter 1/1 - loss 3.06340156 - time (sec): 0.82 - samples/sec: 981.65 - lr: 0.100000 - momentum: 0.000000
2023-12-06 21:27:55,861 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:55,862 EPOCH 2 done: loss 3.0634 - lr: 0.100000
100%|██████████| 1/1 [00:00<00:00,  9.01it/s]
2023-12-06 21:27:55,995 DEV : loss 2.6489498615264893 - f1-score (micro avg)  0.0
2023-12-06 21:27:55,997  - 1 epochs without improvement
2023-12-06 21:27:55,999 ----------------------------------------------------------------------------------------------------

2023-12-06 21:27:56,861 epoch 3 - iter 1/1 - loss 2.43729423 - time (sec): 0.86 - samples/sec: 932.69 - lr: 0.100000 - momentum: 0.000000
2023-12-06 21:27:56,862 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:56,863 EPOCH 3 done: loss 2.4373 - lr: 0.100000
100%|██████████| 1/1 [00:00<00:00,  8.62it/s]
2023-12-06 21:27:56,999 DEV : loss 2.7403860092163086 - f1-score (micro avg)  0.0
2023-12-06 21:27:57,002  - 2 epochs without improvement
2023-12-06 21:27:57,004 ----------------------------------------------------------------------------------------------------

2023-12-06 21:27:57,839 epoch 4 - iter 1/1 - loss 2.31072493 - time (sec): 0.83 - samples/sec: 962.86 - lr: 0.100000 - momentum: 0.000000
2023-12-06 21:27:57,840 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:57,841 EPOCH 4 done: loss 2.3107 - lr: 0.100000
100%|██████████| 1/1 [00:00<00:00, 12.86it/s]
2023-12-06 21:27:57,938 DEV : loss 2.439244508743286 - f1-score (micro avg)  0.027
2023-12-06 21:27:57,940  - 3 epochs without improvement
2023-12-06 21:27:57,942 ----------------------------------------------------------------------------------------------------

2023-12-06 21:27:58,730 epoch 5 - iter 1/1 - loss 2.21886054 - time (sec): 0.79 - samples/sec: 1019.28 - lr: 0.100000 - momentum: 0.000000
2023-12-06 21:27:58,732 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:58,733 EPOCH 5 done: loss 2.2189 - lr: 0.100000
100%|██████████| 1/1 [00:00<00:00, 12.65it/s]
2023-12-06 21:27:58,831 DEV : loss 2.6237685680389404 - f1-score (micro avg)  0.0
2023-12-06 21:27:58,834  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.05]
2023-12-06 21:27:58,835 ----------------------------------------------------------------------------------------------------

2023-12-06 21:27:59,717 epoch 6 - iter 1/1 - loss 2.19103198 - time (sec): 0.88 - samples/sec: 911.64 - lr: 0.050000 - momentum: 0.000000
2023-12-06 21:27:59,719 ----------------------------------------------------------------------------------------------------
2023-12-06 21:27:59,720 EPOCH 6 done: loss 2.1910 - lr: 0.050000
100%|██████████| 1/1 [00:00<00:00, 13.06it/s]
2023-12-06 21:27:59,816 DEV : loss 2.3048999309539795 - f1-score (micro avg)  0.0444
2023-12-06 21:27:59,819  - 0 epochs without improvement
2023-12-06 21:27:59,820 saving best model

2023-12-06 21:28:02,540 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:03,502 epoch 7 - iter 1/1 - loss 2.00259507 - time (sec): 0.96 - samples/sec: 836.12 - lr: 0.050000 - momentum: 0.000000
2023-12-06 21:28:03,504 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:03,506 EPOCH 7 done: loss 2.0026 - lr: 0.050000
100%|██████████| 1/1 [00:00<00:00,  9.35it/s]
2023-12-06 21:28:03,634 DEV : loss 2.2567508220672607 - f1-score (micro avg)  0.0455
2023-12-06 21:28:03,638  - 0 epochs without improvement
2023-12-06 21:28:03,640 saving best model

2023-12-06 21:28:06,443 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:07,283 epoch 8 - iter 1/1 - loss 1.90760329 - time (sec): 0.84 - samples/sec: 958.75 - lr: 0.050000 - momentum: 0.000000
2023-12-06 21:28:07,284 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:07,285 EPOCH 8 done: loss 1.9076 - lr: 0.050000
100%|██████████| 1/1 [00:00<00:00, 13.14it/s]
2023-12-06 21:28:07,382 DEV : loss 2.1499483585357666 - f1-score (micro avg)  0.0385
2023-12-06 21:28:07,385  - 1 epochs without improvement
2023-12-06 21:28:07,386 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:08,212 epoch 9 - iter 1/1 - loss 1.83947399 - time (sec): 0.82 - samples/sec: 973.92 - lr: 0.050000 - momentum: 0.000000
2023-12-06 21:28:08,215 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:08,216 EPOCH 9 done: loss 1.8395 - lr: 0.050000
100%|██████████| 1/1 [00:00<00:00,  8.99it/s]
2023-12-06 21:28:08,347 DEV : loss 2.138460159301758 - f1-score (micro avg)  0.0408
2023-12-06 21:28:08,350  - 2 epochs without improvement
2023-12-06 21:28:08,351 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:09,214 epoch 10 - iter 1/1 - loss 1.77497615 - time (sec): 0.86 - samples/sec: 931.46 - lr: 0.050000 - momentum: 0.000000
2023-12-06 21:28:09,218 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:09,219 EPOCH 10 done: loss 1.7750 - lr: 0.050000
100%|██████████| 1/1 [00:00<00:00, 12.36it/s]
2023-12-06 21:28:09,321 DEV : loss 1.9972478151321411 - f1-score (micro avg)  0.029
2023-12-06 21:28:09,324  - 3 epochs without improvement
2023-12-06 21:28:09,327 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:10,177 epoch 11 - iter 1/1 - loss 1.72156076 - time (sec): 0.85 - samples/sec: 946.33 - lr: 0.050000 - momentum: 0.000000
2023-12-06 21:28:10,179 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:10,179 EPOCH 11 done: loss 1.7216 - lr: 0.050000
100%|██████████| 1/1 [00:00<00:00,  9.09it/s]
2023-12-06 21:28:10,308 DEV : loss 2.1225645542144775 - f1-score (micro avg)  0.0426
2023-12-06 21:28:10,311  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.025]
2023-12-06 21:28:10,313 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:11,128 epoch 12 - iter 1/1 - loss 1.72025606 - time (sec): 0.81 - samples/sec: 987.11 - lr: 0.025000 - momentum: 0.000000
2023-12-06 21:28:11,129 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:11,130 EPOCH 12 done: loss 1.7203 - lr: 0.025000
100%|██████████| 1/1 [00:00<00:00, 12.86it/s]
2023-12-06 21:28:11,226 DEV : loss 1.9664490222930908 - f1-score (micro avg)  0.0317
2023-12-06 21:28:11,229  - 1 epochs without improvement
2023-12-06 21:28:11,231 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:12,002 epoch 13 - iter 1/1 - loss 1.66056334 - time (sec): 0.77 - samples/sec: 1043.11 - lr: 0.025000 - momentum: 0.000000
2023-12-06 21:28:12,004 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:12,004 EPOCH 13 done: loss 1.6606 - lr: 0.025000
100%|██████████| 1/1 [00:00<00:00, 12.39it/s]
2023-12-06 21:28:12,105 DEV : loss 1.9176743030548096 - f1-score (micro avg)  0.029
2023-12-06 21:28:12,108  - 2 epochs without improvement
2023-12-06 21:28:12,109 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:12,942 epoch 14 - iter 1/1 - loss 1.61634482 - time (sec): 0.83 - samples/sec: 965.17 - lr: 0.025000 - momentum: 0.000000
2023-12-06 21:28:12,944 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:12,945 EPOCH 14 done: loss 1.6163 - lr: 0.025000
100%|██████████| 1/1 [00:00<00:00,  9.83it/s]
2023-12-06 21:28:13,068 DEV : loss 1.9391270875930786 - f1-score (micro avg)  0.0323
2023-12-06 21:28:13,070  - 3 epochs without improvement
2023-12-06 21:28:13,072 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:13,901 epoch 15 - iter 1/1 - loss 1.59591067 - time (sec): 0.83 - samples/sec: 970.04 - lr: 0.025000 - momentum: 0.000000
2023-12-06 21:28:13,902 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:13,903 EPOCH 15 done: loss 1.5959 - lr: 0.025000
100%|██████████| 1/1 [00:00<00:00, 11.99it/s]
2023-12-06 21:28:14,006 DEV : loss 1.8808469772338867 - f1-score (micro avg)  0.0299
2023-12-06 21:28:14,009  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.0125]
2023-12-06 21:28:14,011 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:14,851 epoch 16 - iter 1/1 - loss 1.59386111 - time (sec): 0.84 - samples/sec: 958.50 - lr: 0.012500 - momentum: 0.000000
2023-12-06 21:28:14,852 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:14,853 EPOCH 16 done: loss 1.5939 - lr: 0.012500
100%|██████████| 1/1 [00:00<00:00, 12.44it/s]
2023-12-06 21:28:14,953 DEV : loss 1.8669466972351074 - f1-score (micro avg)  0.0294
2023-12-06 21:28:14,956  - 1 epochs without improvement
2023-12-06 21:28:14,958 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:15,777 epoch 17 - iter 1/1 - loss 1.55392233 - time (sec): 0.82 - samples/sec: 981.48 - lr: 0.012500 - momentum: 0.000000
2023-12-06 21:28:15,778 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:15,780 EPOCH 17 done: loss 1.5539 - lr: 0.012500
100%|██████████| 1/1 [00:00<00:00,  9.14it/s]
2023-12-06 21:28:15,908 DEV : loss 1.8656595945358276 - f1-score (micro avg)  0.0299
2023-12-06 21:28:15,911  - 2 epochs without improvement
2023-12-06 21:28:15,914 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:16,773 epoch 18 - iter 1/1 - loss 1.53566347 - time (sec): 0.86 - samples/sec: 936.18 - lr: 0.012500 - momentum: 0.000000
2023-12-06 21:28:16,774 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:16,775 EPOCH 18 done: loss 1.5357 - lr: 0.012500
100%|██████████| 1/1 [00:00<00:00, 10.36it/s]
2023-12-06 21:28:16,890 DEV : loss 1.857499599456787 - f1-score (micro avg)  0.0299
2023-12-06 21:28:16,893  - 3 epochs without improvement
2023-12-06 21:28:16,894 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:17,826 epoch 19 - iter 1/1 - loss 1.53728466 - time (sec): 0.93 - samples/sec: 863.11 - lr: 0.012500 - momentum: 0.000000
2023-12-06 21:28:17,827 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:17,828 EPOCH 19 done: loss 1.5373 - lr: 0.012500
100%|██████████| 1/1 [00:00<00:00,  9.76it/s]
2023-12-06 21:28:17,950 DEV : loss 1.8376151323318481 - f1-score (micro avg)  0.0294
2023-12-06 21:28:17,953  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.00625]
2023-12-06 21:28:17,954 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:18,739 epoch 20 - iter 1/1 - loss 1.53566620 - time (sec): 0.78 - samples/sec: 1024.21 - lr: 0.006250 - momentum: 0.000000
2023-12-06 21:28:18,740 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:18,741 EPOCH 20 done: loss 1.5357 - lr: 0.006250
100%|██████████| 1/1 [00:00<00:00, 12.76it/s]
2023-12-06 21:28:18,838 DEV : loss 1.8346071243286133 - f1-score (micro avg)  0.029
2023-12-06 21:28:18,841  - 1 epochs without improvement
2023-12-06 21:28:18,842 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:19,633 epoch 21 - iter 1/1 - loss 1.53173860 - time (sec): 0.79 - samples/sec: 1016.00 - lr: 0.006250 - momentum: 0.000000
2023-12-06 21:28:19,635 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:19,636 EPOCH 21 done: loss 1.5317 - lr: 0.006250
100%|██████████| 1/1 [00:00<00:00,  9.71it/s]
2023-12-06 21:28:19,758 DEV : loss 1.8182944059371948 - f1-score (micro avg)  0.0286
2023-12-06 21:28:19,760  - 2 epochs without improvement
2023-12-06 21:28:19,761 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:20,607 epoch 22 - iter 1/1 - loss 1.53337986 - time (sec): 0.84 - samples/sec: 951.25 - lr: 0.006250 - momentum: 0.000000
2023-12-06 21:28:20,608 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:20,609 EPOCH 22 done: loss 1.5334 - lr: 0.006250
100%|██████████| 1/1 [00:00<00:00, 12.92it/s]
2023-12-06 21:28:20,705 DEV : loss 1.811253547668457 - f1-score (micro avg)  0.0282
2023-12-06 21:28:20,707  - 3 epochs without improvement
2023-12-06 21:28:20,708 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:21,544 epoch 23 - iter 1/1 - loss 1.47820222 - time (sec): 0.83 - samples/sec: 962.30 - lr: 0.006250 - momentum: 0.000000
2023-12-06 21:28:21,545 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:21,546 EPOCH 23 done: loss 1.4782 - lr: 0.006250
100%|██████████| 1/1 [00:00<00:00,  9.83it/s]
2023-12-06 21:28:21,667 DEV : loss 1.8028925657272339 - f1-score (micro avg)  0.0282
2023-12-06 21:28:21,670  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.003125]
2023-12-06 21:28:21,672 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:22,458 epoch 24 - iter 1/1 - loss 1.48230398 - time (sec): 0.78 - samples/sec: 1024.06 - lr: 0.003125 - momentum: 0.000000
2023-12-06 21:28:22,459 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:22,460 EPOCH 24 done: loss 1.4823 - lr: 0.003125
100%|██████████| 1/1 [00:00<00:00, 12.30it/s]
2023-12-06 21:28:22,561 DEV : loss 1.8002527952194214 - f1-score (micro avg)  0.0278
2023-12-06 21:28:22,565  - 1 epochs without improvement
2023-12-06 21:28:22,566 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:23,419 epoch 25 - iter 1/1 - loss 1.47203858 - time (sec): 0.85 - samples/sec: 943.01 - lr: 0.003125 - momentum: 0.000000
2023-12-06 21:28:23,421 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:23,422 EPOCH 25 done: loss 1.4720 - lr: 0.003125
100%|██████████| 1/1 [00:00<00:00, 12.61it/s]
2023-12-06 21:28:23,520 DEV : loss 1.7987778186798096 - f1-score (micro avg)  0.0278
2023-12-06 21:28:23,523  - 2 epochs without improvement
2023-12-06 21:28:23,524 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:24,336 epoch 26 - iter 1/1 - loss 1.50435344 - time (sec): 0.81 - samples/sec: 990.60 - lr: 0.003125 - momentum: 0.000000
2023-12-06 21:28:24,338 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:24,340 EPOCH 26 done: loss 1.5044 - lr: 0.003125
100%|██████████| 1/1 [00:00<00:00,  9.47it/s]
2023-12-06 21:28:24,464 DEV : loss 1.798949122428894 - f1-score (micro avg)  0.0278
2023-12-06 21:28:24,467  - 3 epochs without improvement
2023-12-06 21:28:24,469 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:25,298 epoch 27 - iter 1/1 - loss 1.48610904 - time (sec): 0.83 - samples/sec: 969.19 - lr: 0.003125 - momentum: 0.000000
2023-12-06 21:28:25,300 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:25,301 EPOCH 27 done: loss 1.4861 - lr: 0.003125
100%|██████████| 1/1 [00:00<00:00, 12.31it/s]
2023-12-06 21:28:25,401 DEV : loss 1.8025261163711548 - f1-score (micro avg)  0.0286
2023-12-06 21:28:25,404  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.0015625]
2023-12-06 21:28:25,405 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:26,191 epoch 28 - iter 1/1 - loss 1.50742752 - time (sec): 0.78 - samples/sec: 1022.94 - lr: 0.001563 - momentum: 0.000000
2023-12-06 21:28:26,192 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:26,193 EPOCH 28 done: loss 1.5074 - lr: 0.001563
100%|██████████| 1/1 [00:00<00:00, 12.86it/s]
2023-12-06 21:28:26,289 DEV : loss 1.8043862581253052 - f1-score (micro avg)  0.0286
2023-12-06 21:28:26,292  - 1 epochs without improvement
2023-12-06 21:28:26,293 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:27,105 epoch 29 - iter 1/1 - loss 1.49105027 - time (sec): 0.81 - samples/sec: 990.68 - lr: 0.001563 - momentum: 0.000000
2023-12-06 21:28:27,107 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:27,108 EPOCH 29 done: loss 1.4911 - lr: 0.001563
100%|██████████| 1/1 [00:00<00:00, 12.88it/s]
2023-12-06 21:28:27,206 DEV : loss 1.8049720525741577 - f1-score (micro avg)  0.0286
2023-12-06 21:28:27,209  - 2 epochs without improvement
2023-12-06 21:28:27,210 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:27,993 epoch 30 - iter 1/1 - loss 1.48577747 - time (sec): 0.78 - samples/sec: 1027.25 - lr: 0.001563 - momentum: 0.000000
2023-12-06 21:28:27,994 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:27,995 EPOCH 30 done: loss 1.4858 - lr: 0.001563
100%|██████████| 1/1 [00:00<00:00, 13.13it/s]
2023-12-06 21:28:28,091 DEV : loss 1.8038734197616577 - f1-score (micro avg)  0.029
2023-12-06 21:28:28,094  - 3 epochs without improvement
2023-12-06 21:28:28,095 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:28,899 epoch 31 - iter 1/1 - loss 1.46302585 - time (sec): 0.80 - samples/sec: 1000.60 - lr: 0.001563 - momentum: 0.000000
2023-12-06 21:28:28,901 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:28,902 EPOCH 31 done: loss 1.4630 - lr: 0.001563
100%|██████████| 1/1 [00:00<00:00, 12.57it/s]
2023-12-06 21:28:29,000 DEV : loss 1.8024020195007324 - f1-score (micro avg)  0.0286
2023-12-06 21:28:29,003  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.00078125]
2023-12-06 21:28:29,004 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:29,803 epoch 32 - iter 1/1 - loss 1.48712105 - time (sec): 0.80 - samples/sec: 1006.53 - lr: 0.000781 - momentum: 0.000000
2023-12-06 21:28:29,805 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:29,806 EPOCH 32 done: loss 1.4871 - lr: 0.000781
100%|██████████| 1/1 [00:00<00:00,  9.69it/s]
2023-12-06 21:28:29,929 DEV : loss 1.8001490831375122 - f1-score (micro avg)  0.0286
2023-12-06 21:28:29,932  - 1 epochs without improvement
2023-12-06 21:28:29,933 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:30,760 epoch 33 - iter 1/1 - loss 1.48832310 - time (sec): 0.83 - samples/sec: 972.13 - lr: 0.000781 - momentum: 0.000000
2023-12-06 21:28:30,762 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:30,763 EPOCH 33 done: loss 1.4883 - lr: 0.000781
100%|██████████| 1/1 [00:00<00:00, 12.63it/s]
2023-12-06 21:28:30,860 DEV : loss 1.7981985807418823 - f1-score (micro avg)  0.0286
2023-12-06 21:28:30,863  - 2 epochs without improvement
2023-12-06 21:28:30,864 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:31,630 epoch 34 - iter 1/1 - loss 1.47803679 - time (sec): 0.76 - samples/sec: 1049.83 - lr: 0.000781 - momentum: 0.000000
2023-12-06 21:28:31,632 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:31,633 EPOCH 34 done: loss 1.4780 - lr: 0.000781
100%|██████████| 1/1 [00:00<00:00, 11.19it/s]
2023-12-06 21:28:31,743 DEV : loss 1.7957336902618408 - f1-score (micro avg)  0.0286
2023-12-06 21:28:31,747  - 3 epochs without improvement
2023-12-06 21:28:31,749 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:32,545 epoch 35 - iter 1/1 - loss 1.48464227 - time (sec): 0.79 - samples/sec: 1010.08 - lr: 0.000781 - momentum: 0.000000
2023-12-06 21:28:32,547 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:32,548 EPOCH 35 done: loss 1.4846 - lr: 0.000781
100%|██████████| 1/1 [00:00<00:00, 12.65it/s]
2023-12-06 21:28:32,647 DEV : loss 1.7956260442733765 - f1-score (micro avg)  0.0286
2023-12-06 21:28:32,651  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.000390625]
2023-12-06 21:28:32,652 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:33,471 epoch 36 - iter 1/1 - loss 1.48402520 - time (sec): 0.82 - samples/sec: 982.57 - lr: 0.000391 - momentum: 0.000000
2023-12-06 21:28:33,473 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:33,475 EPOCH 36 done: loss 1.4840 - lr: 0.000391
100%|██████████| 1/1 [00:00<00:00,  8.53it/s]
2023-12-06 21:28:33,613 DEV : loss 1.7944562435150146 - f1-score (micro avg)  0.0286
2023-12-06 21:28:33,616  - 1 epochs without improvement
2023-12-06 21:28:33,617 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:34,460 epoch 37 - iter 1/1 - loss 1.48426125 - time (sec): 0.84 - samples/sec: 953.80 - lr: 0.000391 - momentum: 0.000000
2023-12-06 21:28:34,462 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:34,463 EPOCH 37 done: loss 1.4843 - lr: 0.000391
100%|██████████| 1/1 [00:00<00:00,  8.36it/s]
2023-12-06 21:28:34,602 DEV : loss 1.793975830078125 - f1-score (micro avg)  0.0286
2023-12-06 21:28:34,604  - 2 epochs without improvement
2023-12-06 21:28:34,605 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:35,523 epoch 38 - iter 1/1 - loss 1.46144871 - time (sec): 0.92 - samples/sec: 875.51 - lr: 0.000391 - momentum: 0.000000
2023-12-06 21:28:35,525 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:35,526 EPOCH 38 done: loss 1.4614 - lr: 0.000391
100%|██████████| 1/1 [00:00<00:00, 12.49it/s]
2023-12-06 21:28:35,626 DEV : loss 1.7946051359176636 - f1-score (micro avg)  0.0286
2023-12-06 21:28:35,630  - 3 epochs without improvement
2023-12-06 21:28:35,631 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:36,407 epoch 39 - iter 1/1 - loss 1.45723285 - time (sec): 0.77 - samples/sec: 1037.45 - lr: 0.000391 - momentum: 0.000000
2023-12-06 21:28:36,408 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:36,409 EPOCH 39 done: loss 1.4572 - lr: 0.000391
100%|██████████| 1/1 [00:00<00:00, 12.07it/s]
2023-12-06 21:28:36,512 DEV : loss 1.7950620651245117 - f1-score (micro avg)  0.0286
2023-12-06 21:28:36,515  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.0001953125]
2023-12-06 21:28:36,516 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:37,373 epoch 40 - iter 1/1 - loss 1.47416760 - time (sec): 0.86 - samples/sec: 938.95 - lr: 0.000195 - momentum: 0.000000
2023-12-06 21:28:37,374 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:37,375 EPOCH 40 done: loss 1.4742 - lr: 0.000195
100%|██████████| 1/1 [00:00<00:00, 13.03it/s]
2023-12-06 21:28:37,471 DEV : loss 1.795048713684082 - f1-score (micro avg)  0.0286
2023-12-06 21:28:37,474  - 1 epochs without improvement
2023-12-06 21:28:37,475 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:38,286 epoch 41 - iter 1/1 - loss 1.46946931 - time (sec): 0.81 - samples/sec: 991.86 - lr: 0.000195 - momentum: 0.000000
2023-12-06 21:28:38,288 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:38,288 EPOCH 41 done: loss 1.4695 - lr: 0.000195
100%|██████████| 1/1 [00:00<00:00,  8.86it/s]
2023-12-06 21:28:38,420 DEV : loss 1.7948156595230103 - f1-score (micro avg)  0.0286
2023-12-06 21:28:38,423  - 2 epochs without improvement
2023-12-06 21:28:38,424 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:39,192 epoch 42 - iter 1/1 - loss 1.46764736 - time (sec): 0.77 - samples/sec: 1048.29 - lr: 0.000195 - momentum: 0.000000
2023-12-06 21:28:39,194 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:39,194 EPOCH 42 done: loss 1.4676 - lr: 0.000195
100%|██████████| 1/1 [00:00<00:00, 13.02it/s]
2023-12-06 21:28:39,289 DEV : loss 1.7943202257156372 - f1-score (micro avg)  0.0286
2023-12-06 21:28:39,292  - 3 epochs without improvement
2023-12-06 21:28:39,293 ----------------------------------------------------------------------------------------------------

2023-12-06 21:28:40,082 epoch 43 - iter 1/1 - loss 1.47038098 - time (sec): 0.79 - samples/sec: 1018.93 - lr: 0.000195 - momentum: 0.000000
2023-12-06 21:28:40,084 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:40,085 EPOCH 43 done: loss 1.4704 - lr: 0.000195
100%|██████████| 1/1 [00:00<00:00,  9.33it/s]
2023-12-06 21:28:40,211 DEV : loss 1.7944234609603882 - f1-score (micro avg)  0.0286
2023-12-06 21:28:40,214  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [9.765625e-05]
2023-12-06 21:28:40,215 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:40,216 learning rate too small - quitting training!
2023-12-06 21:28:40,217 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:40,218 Saving model ...

2023-12-06 21:28:42,985 Done.
2023-12-06 21:28:42,986 ----------------------------------------------------------------------------------------------------
2023-12-06 21:28:42,987 Loading model from best epoch ...
2023-12-06 21:28:44,013 SequenceTagger predicts: Dictionary with 27 tags: O, S-Funding Agency, B-Funding Agency, E-Funding Agency, I-Funding Agency, S-Grant Number, B-Grant Number, E-Grant Number, I-Grant Number, S-Person, B-Person, E-Person, I-Person, S-Corporation, B-Corporation, E-Corporation, I-Corporation, S-University, B-University, E-University, I-University, S-Miscellaneous, B-Miscellaneous, E-Miscellaneous, I-Miscellaneous, <START>, <STOP>
100%|██████████| 1/1 [00:01<00:00,  1.10s/it]
2023-12-06 21:28:45,400 
Results:
- F-score (micro) 0.0
- F-score (macro) 0.0
- Accuracy 0.0

By class:
                precision    recall  f1-score   support

Funding Agency     0.0000    0.0000    0.0000      20.0
        Person     0.0000    0.0000    0.0000      12.0
  Grant Number     0.0000    0.0000    0.0000      11.0
 Miscellaneous     0.0000    0.0000    0.0000       9.0
    University     0.0000    0.0000    0.0000       5.0
   Corporation     0.0000    0.0000    0.0000       1.0

     micro avg     0.0000    0.0000    0.0000      58.0
     macro avg     0.0000    0.0000    0.0000      58.0
  weighted avg     0.0000    0.0000    0.0000      58.0

2023-12-06 21:28:45,401 ----------------------------------------------------------------------------------------------------

{'test_score': 0.0}