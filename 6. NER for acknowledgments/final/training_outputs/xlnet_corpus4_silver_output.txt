2023-12-10 14:33:21,066 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,068 Model: "SequenceTagger(
  (embeddings): TransformerWordEmbeddings(
    (model): XLNetModel(
      (word_embedding): Embedding(32001, 1024)
      (layer): ModuleList(
        (0-23): 24 x XLNetLayer(
          (rel_attn): XLNetRelativeAttention(
            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ff): XLNetFeedForward(
            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (activation_function): GELUActivation()
          )
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1024, out_features=25, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2023-12-10 14:33:21,069 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,071 Corpus: 1386 train + 150 dev + 164 test sentences
2023-12-10 14:33:21,072 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,073 Train:  1386 sentences
2023-12-10 14:33:21,074         (train_with_dev=False, train_with_test=False)
2023-12-10 14:33:21,075 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,075 Training Params:
2023-12-10 14:33:21,076  - learning_rate: "0.01" 
2023-12-10 14:33:21,077  - mini_batch_size: "4"
2023-12-10 14:33:21,078  - max_epochs: "10"
2023-12-10 14:33:21,079  - shuffle: "True"
2023-12-10 14:33:21,080 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,081 Plugins:
2023-12-10 14:33:21,081  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'
2023-12-10 14:33:21,082 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,083 Final evaluation on model from best epoch (best-model.pt)
2023-12-10 14:33:21,084  - metric: "('micro avg', 'f1-score')"
2023-12-10 14:33:21,085 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,085 Computation:
2023-12-10 14:33:21,086  - compute on device: cpu
2023-12-10 14:33:21,087  - embedding storage: none
2023-12-10 14:33:21,088 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,089 Model training base path: "resources/taggers/xlnet4-silver"
2023-12-10 14:33:21,090 ----------------------------------------------------------------------------------------------------
2023-12-10 14:33:21,091 ----------------------------------------------------------------------------------------------------
2023-12-10 14:37:37,156 epoch 1 - iter 34/347 - loss 4.06732048 - time (sec): 256.06 - samples/sec: 26.06 - lr: 0.010000 - momentum: 0.000000
2023-12-10 14:41:27,618 epoch 1 - iter 68/347 - loss 3.25379076 - time (sec): 486.52 - samples/sec: 24.65 - lr: 0.010000 - momentum: 0.000000
2023-12-10 14:45:39,146 epoch 1 - iter 102/347 - loss 2.77650416 - time (sec): 738.05 - samples/sec: 24.48 - lr: 0.010000 - momentum: 0.000000
2023-12-10 14:49:02,232 epoch 1 - iter 136/347 - loss 2.52704183 - time (sec): 941.14 - samples/sec: 24.37 - lr: 0.010000 - momentum: 0.000000
2023-12-10 14:52:10,778 epoch 1 - iter 170/347 - loss 2.30738715 - time (sec): 1129.69 - samples/sec: 24.77 - lr: 0.010000 - momentum: 0.000000
2023-12-10 14:55:40,991 epoch 1 - iter 204/347 - loss 2.16477450 - time (sec): 1339.90 - samples/sec: 24.92 - lr: 0.010000 - momentum: 0.000000
2023-12-10 14:59:55,459 epoch 1 - iter 238/347 - loss 2.00681127 - time (sec): 1594.37 - samples/sec: 25.07 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:03:24,973 epoch 1 - iter 272/347 - loss 1.90476072 - time (sec): 1803.88 - samples/sec: 24.97 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:07:11,460 epoch 1 - iter 306/347 - loss 1.80852305 - time (sec): 2030.37 - samples/sec: 24.75 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:11:14,711 epoch 1 - iter 340/347 - loss 1.73385790 - time (sec): 2273.62 - samples/sec: 24.06 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:11:51,379 ----------------------------------------------------------------------------------------------------
2023-12-10 15:11:51,381 EPOCH 1 done: loss 1.7233 - lr: 0.010000
2023-12-10 15:15:34,739 DEV : loss 1.0408821105957031 - f1-score (micro avg)  0.5122
2023-12-10 15:15:34,746  - 0 epochs without improvement
2023-12-10 15:15:34,748 saving best model
2023-12-10 15:15:37,753 ----------------------------------------------------------------------------------------------------
2023-12-10 15:19:16,662 epoch 2 - iter 34/347 - loss 0.90791104 - time (sec): 218.91 - samples/sec: 25.35 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:22:51,860 epoch 2 - iter 68/347 - loss 0.85986917 - time (sec): 434.10 - samples/sec: 24.40 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:27:08,820 epoch 2 - iter 102/347 - loss 0.89831923 - time (sec): 691.06 - samples/sec: 23.31 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:30:38,850 epoch 2 - iter 136/347 - loss 0.88432356 - time (sec): 901.09 - samples/sec: 23.54 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:34:20,844 epoch 2 - iter 170/347 - loss 0.84755179 - time (sec): 1123.09 - samples/sec: 24.15 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:37:52,492 epoch 2 - iter 204/347 - loss 0.81078451 - time (sec): 1334.74 - samples/sec: 24.21 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:41:42,896 epoch 2 - iter 238/347 - loss 0.78921347 - time (sec): 1565.14 - samples/sec: 24.29 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:45:19,203 epoch 2 - iter 272/347 - loss 0.77375903 - time (sec): 1781.45 - samples/sec: 24.44 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:49:26,966 epoch 2 - iter 306/347 - loss 0.75122796 - time (sec): 2029.21 - samples/sec: 24.45 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:52:54,601 epoch 2 - iter 340/347 - loss 0.73222491 - time (sec): 2236.85 - samples/sec: 24.53 - lr: 0.010000 - momentum: 0.000000
2023-12-10 15:53:34,359 ----------------------------------------------------------------------------------------------------
2023-12-10 15:53:34,360 EPOCH 2 done: loss 0.7275 - lr: 0.010000
2023-12-10 15:57:23,352 DEV : loss 0.6421820521354675 - f1-score (micro avg)  0.6573
2023-12-10 15:57:23,358  - 0 epochs without improvement
2023-12-10 15:57:23,360 saving best model
2023-12-10 15:57:31,964 ----------------------------------------------------------------------------------------------------
2023-12-10 16:00:57,424 epoch 3 - iter 34/347 - loss 0.56829743 - time (sec): 205.46 - samples/sec: 25.31 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:04:42,890 epoch 3 - iter 68/347 - loss 0.57517953 - time (sec): 430.92 - samples/sec: 24.67 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:09:02,860 epoch 3 - iter 102/347 - loss 0.54896947 - time (sec): 690.89 - samples/sec: 23.11 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:13:55,800 epoch 3 - iter 136/347 - loss 0.54301007 - time (sec): 983.83 - samples/sec: 22.27 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:17:28,989 epoch 3 - iter 170/347 - loss 0.51270480 - time (sec): 1197.02 - samples/sec: 22.79 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:20:59,907 epoch 3 - iter 204/347 - loss 0.49804251 - time (sec): 1407.94 - samples/sec: 23.17 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:26:30,276 epoch 3 - iter 238/347 - loss 0.51234593 - time (sec): 1738.31 - samples/sec: 21.92 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:30:46,118 epoch 3 - iter 272/347 - loss 0.49999152 - time (sec): 1994.15 - samples/sec: 22.16 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:34:07,540 epoch 3 - iter 306/347 - loss 0.49919745 - time (sec): 2195.57 - samples/sec: 22.23 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:37:45,569 epoch 3 - iter 340/347 - loss 0.49171784 - time (sec): 2413.60 - samples/sec: 22.37 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:38:51,051 ----------------------------------------------------------------------------------------------------
2023-12-10 16:38:51,053 EPOCH 3 done: loss 0.4884 - lr: 0.010000
2023-12-10 16:42:46,460 DEV : loss 0.491461843252182 - f1-score (micro avg)  0.7318
2023-12-10 16:42:46,468  - 0 epochs without improvement
2023-12-10 16:42:46,470 saving best model
2023-12-10 16:42:55,354 ----------------------------------------------------------------------------------------------------
2023-12-10 16:47:10,126 epoch 4 - iter 34/347 - loss 0.46061482 - time (sec): 254.77 - samples/sec: 26.38 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:51:05,175 epoch 4 - iter 68/347 - loss 0.44551545 - time (sec): 489.82 - samples/sec: 26.08 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:54:37,985 epoch 4 - iter 102/347 - loss 0.43133647 - time (sec): 702.63 - samples/sec: 25.54 - lr: 0.010000 - momentum: 0.000000
2023-12-10 16:58:01,071 epoch 4 - iter 136/347 - loss 0.42630421 - time (sec): 905.71 - samples/sec: 24.75 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:01:56,724 epoch 4 - iter 170/347 - loss 0.42697954 - time (sec): 1141.37 - samples/sec: 24.54 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:06:31,188 epoch 4 - iter 204/347 - loss 0.42883591 - time (sec): 1415.83 - samples/sec: 24.19 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:10:07,574 epoch 4 - iter 238/347 - loss 0.41801164 - time (sec): 1632.22 - samples/sec: 24.10 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:13:50,857 epoch 4 - iter 272/347 - loss 0.40702587 - time (sec): 1855.50 - samples/sec: 23.96 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:18:59,787 epoch 4 - iter 306/347 - loss 0.40413824 - time (sec): 2164.43 - samples/sec: 23.11 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:22:47,575 epoch 4 - iter 340/347 - loss 0.39854418 - time (sec): 2392.22 - samples/sec: 22.94 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:23:29,379 ----------------------------------------------------------------------------------------------------
2023-12-10 17:23:29,381 EPOCH 4 done: loss 0.3996 - lr: 0.010000
2023-12-10 17:27:12,961 DEV : loss 0.4654630124568939 - f1-score (micro avg)  0.7333
2023-12-10 17:27:12,967  - 0 epochs without improvement
2023-12-10 17:27:12,969 saving best model
2023-12-10 17:27:21,808 ----------------------------------------------------------------------------------------------------
2023-12-10 17:31:27,893 epoch 5 - iter 34/347 - loss 0.38770309 - time (sec): 246.08 - samples/sec: 23.79 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:35:27,460 epoch 5 - iter 68/347 - loss 0.39296430 - time (sec): 485.65 - samples/sec: 23.17 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:39:17,821 epoch 5 - iter 102/347 - loss 0.37327353 - time (sec): 716.01 - samples/sec: 23.82 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:42:57,114 epoch 5 - iter 136/347 - loss 0.37110215 - time (sec): 935.30 - samples/sec: 24.61 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:46:30,574 epoch 5 - iter 170/347 - loss 0.36140880 - time (sec): 1148.76 - samples/sec: 24.26 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:51:29,084 epoch 5 - iter 204/347 - loss 0.35079995 - time (sec): 1447.27 - samples/sec: 22.71 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:54:38,552 epoch 5 - iter 238/347 - loss 0.33972858 - time (sec): 1636.74 - samples/sec: 22.74 - lr: 0.010000 - momentum: 0.000000
2023-12-10 17:58:54,109 epoch 5 - iter 272/347 - loss 0.34176551 - time (sec): 1892.30 - samples/sec: 22.69 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:02:49,948 epoch 5 - iter 306/347 - loss 0.33946279 - time (sec): 2128.14 - samples/sec: 22.91 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:06:32,841 epoch 5 - iter 340/347 - loss 0.34690065 - time (sec): 2351.03 - samples/sec: 23.09 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:07:13,818 ----------------------------------------------------------------------------------------------------
2023-12-10 18:07:13,819 EPOCH 5 done: loss 0.3443 - lr: 0.010000
2023-12-10 18:10:51,831 DEV : loss 0.440693736076355 - f1-score (micro avg)  0.7666
2023-12-10 18:10:51,839  - 0 epochs without improvement
2023-12-10 18:10:51,841 saving best model
2023-12-10 18:11:01,630 ----------------------------------------------------------------------------------------------------
2023-12-10 18:14:33,064 epoch 6 - iter 34/347 - loss 0.27312025 - time (sec): 211.43 - samples/sec: 22.00 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:18:16,618 epoch 6 - iter 68/347 - loss 0.28168166 - time (sec): 434.98 - samples/sec: 23.07 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:22:47,096 epoch 6 - iter 102/347 - loss 0.30756316 - time (sec): 705.46 - samples/sec: 21.77 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:26:51,524 epoch 6 - iter 136/347 - loss 0.30602082 - time (sec): 949.89 - samples/sec: 21.88 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:31:04,699 epoch 6 - iter 170/347 - loss 0.31755382 - time (sec): 1203.06 - samples/sec: 22.36 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:34:52,424 epoch 6 - iter 204/347 - loss 0.30955590 - time (sec): 1430.79 - samples/sec: 22.43 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:38:37,936 epoch 6 - iter 238/347 - loss 0.30444935 - time (sec): 1656.30 - samples/sec: 22.50 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:42:12,184 epoch 6 - iter 272/347 - loss 0.29466800 - time (sec): 1870.55 - samples/sec: 22.75 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:45:58,806 epoch 6 - iter 306/347 - loss 0.29616789 - time (sec): 2097.17 - samples/sec: 22.95 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:50:20,777 epoch 6 - iter 340/347 - loss 0.29657448 - time (sec): 2359.14 - samples/sec: 23.01 - lr: 0.010000 - momentum: 0.000000
2023-12-10 18:51:19,720 ----------------------------------------------------------------------------------------------------
2023-12-10 18:51:19,721 EPOCH 6 done: loss 0.3019 - lr: 0.010000
2023-12-10 18:55:04,673 DEV : loss 0.41665828227996826 - f1-score (micro avg)  0.78
2023-12-10 18:55:04,679  - 0 epochs without improvement
2023-12-10 18:55:04,682 saving best model
2023-12-10 18:55:13,795 ----------------------------------------------------------------------------------------------------
2023-12-10 18:58:50,500 epoch 7 - iter 34/347 - loss 0.24520898 - time (sec): 216.70 - samples/sec: 23.64 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:02:57,403 epoch 7 - iter 68/347 - loss 0.28180776 - time (sec): 463.60 - samples/sec: 23.58 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:06:58,319 epoch 7 - iter 102/347 - loss 0.26549060 - time (sec): 704.52 - samples/sec: 24.19 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:10:46,256 epoch 7 - iter 136/347 - loss 0.26614501 - time (sec): 932.46 - samples/sec: 24.19 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:14:23,288 epoch 7 - iter 170/347 - loss 0.27108643 - time (sec): 1149.49 - samples/sec: 24.18 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:17:44,088 epoch 7 - iter 204/347 - loss 0.26499113 - time (sec): 1350.29 - samples/sec: 23.95 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:21:19,208 epoch 7 - iter 238/347 - loss 0.26210156 - time (sec): 1565.41 - samples/sec: 23.89 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:25:39,782 epoch 7 - iter 272/347 - loss 0.26687359 - time (sec): 1825.98 - samples/sec: 23.86 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:29:26,754 epoch 7 - iter 306/347 - loss 0.26553423 - time (sec): 2052.96 - samples/sec: 23.83 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:33:25,674 epoch 7 - iter 340/347 - loss 0.26111922 - time (sec): 2291.88 - samples/sec: 23.80 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:34:02,771 ----------------------------------------------------------------------------------------------------
2023-12-10 19:34:02,772 EPOCH 7 done: loss 0.2609 - lr: 0.010000
2023-12-10 19:37:44,103 DEV : loss 0.38000309467315674 - f1-score (micro avg)  0.7834
2023-12-10 19:37:44,111  - 0 epochs without improvement
2023-12-10 19:37:44,112 saving best model
2023-12-10 19:37:52,895 ----------------------------------------------------------------------------------------------------
2023-12-10 19:41:18,081 epoch 8 - iter 34/347 - loss 0.19776347 - time (sec): 205.18 - samples/sec: 23.88 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:45:01,103 epoch 8 - iter 68/347 - loss 0.21177297 - time (sec): 428.20 - samples/sec: 24.61 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:48:37,383 epoch 8 - iter 102/347 - loss 0.21408133 - time (sec): 644.48 - samples/sec: 24.25 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:52:26,484 epoch 8 - iter 136/347 - loss 0.22773891 - time (sec): 873.59 - samples/sec: 24.03 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:55:57,691 epoch 8 - iter 170/347 - loss 0.23227400 - time (sec): 1084.79 - samples/sec: 23.95 - lr: 0.010000 - momentum: 0.000000
2023-12-10 19:59:34,337 epoch 8 - iter 204/347 - loss 0.24078412 - time (sec): 1301.44 - samples/sec: 24.11 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:05:16,692 epoch 8 - iter 238/347 - loss 0.22815094 - time (sec): 1643.79 - samples/sec: 22.73 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:09:23,615 epoch 8 - iter 272/347 - loss 0.23264299 - time (sec): 1890.72 - samples/sec: 23.10 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:13:12,728 epoch 8 - iter 306/347 - loss 0.23585010 - time (sec): 2119.83 - samples/sec: 23.08 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:17:35,383 epoch 8 - iter 340/347 - loss 0.23811022 - time (sec): 2382.48 - samples/sec: 22.74 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:18:23,185 ----------------------------------------------------------------------------------------------------
2023-12-10 20:18:23,186 EPOCH 8 done: loss 0.2365 - lr: 0.010000
2023-12-10 20:22:13,177 DEV : loss 0.41025540232658386 - f1-score (micro avg)  0.7932
2023-12-10 20:22:13,188  - 0 epochs without improvement
2023-12-10 20:22:13,190 saving best model
2023-12-10 20:22:24,129 ----------------------------------------------------------------------------------------------------
2023-12-10 20:26:08,688 epoch 9 - iter 34/347 - loss 0.20667256 - time (sec): 224.55 - samples/sec: 24.59 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:29:36,252 epoch 9 - iter 68/347 - loss 0.20515710 - time (sec): 432.12 - samples/sec: 25.63 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:33:35,739 epoch 9 - iter 102/347 - loss 0.22217541 - time (sec): 671.61 - samples/sec: 25.35 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:37:08,857 epoch 9 - iter 136/347 - loss 0.24672445 - time (sec): 884.72 - samples/sec: 25.24 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:41:28,974 epoch 9 - iter 170/347 - loss 0.24820368 - time (sec): 1144.84 - samples/sec: 23.91 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:45:41,586 epoch 9 - iter 204/347 - loss 0.24086833 - time (sec): 1397.45 - samples/sec: 23.03 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:49:14,538 epoch 9 - iter 238/347 - loss 0.23204178 - time (sec): 1610.41 - samples/sec: 23.29 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:53:36,313 epoch 9 - iter 272/347 - loss 0.22640782 - time (sec): 1872.18 - samples/sec: 23.44 - lr: 0.010000 - momentum: 0.000000
2023-12-10 20:57:28,209 epoch 9 - iter 306/347 - loss 0.23008192 - time (sec): 2104.08 - samples/sec: 23.45 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:01:06,044 epoch 9 - iter 340/347 - loss 0.22923572 - time (sec): 2321.91 - samples/sec: 23.57 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:01:46,203 ----------------------------------------------------------------------------------------------------
2023-12-10 21:01:46,204 EPOCH 9 done: loss 0.2270 - lr: 0.010000
2023-12-10 21:05:32,016 DEV : loss 0.45715710520744324 - f1-score (micro avg)  0.8129
2023-12-10 21:05:32,023  - 0 epochs without improvement
2023-12-10 21:05:32,025 saving best model
2023-12-10 21:05:40,649 ----------------------------------------------------------------------------------------------------
2023-12-10 21:09:24,594 epoch 10 - iter 34/347 - loss 0.22687943 - time (sec): 223.94 - samples/sec: 26.91 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:12:56,683 epoch 10 - iter 68/347 - loss 0.20543168 - time (sec): 436.03 - samples/sec: 25.88 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:17:23,330 epoch 10 - iter 102/347 - loss 0.20499404 - time (sec): 702.68 - samples/sec: 24.13 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:21:08,239 epoch 10 - iter 136/347 - loss 0.19647366 - time (sec): 927.59 - samples/sec: 23.95 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:25:17,032 epoch 10 - iter 170/347 - loss 0.20119376 - time (sec): 1176.38 - samples/sec: 23.61 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:28:59,082 epoch 10 - iter 204/347 - loss 0.20077607 - time (sec): 1398.43 - samples/sec: 23.48 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:32:53,918 epoch 10 - iter 238/347 - loss 0.20309001 - time (sec): 1633.27 - samples/sec: 23.64 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:36:26,692 epoch 10 - iter 272/347 - loss 0.20318155 - time (sec): 1846.04 - samples/sec: 23.70 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:40:07,728 epoch 10 - iter 306/347 - loss 0.20153901 - time (sec): 2067.08 - samples/sec: 23.81 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:43:37,780 epoch 10 - iter 340/347 - loss 0.19684174 - time (sec): 2277.13 - samples/sec: 24.07 - lr: 0.010000 - momentum: 0.000000
2023-12-10 21:44:18,621 ----------------------------------------------------------------------------------------------------
2023-12-10 21:44:18,622 EPOCH 10 done: loss 0.1973 - lr: 0.010000
100%|██████████| 3/3 [05:03<00:00, 101.08s/it]
2023-12-10 21:49:21,905 DEV : loss 0.39276039600372314 - f1-score (micro avg)  0.8078
2023-12-10 21:49:21,912  - 1 epochs without improvement

2023-12-10 21:49:31,666 ----------------------------------------------------------------------------------------------------
2023-12-10 21:49:31,670 Loading model from best epoch ...
2023-12-10 21:49:37,764 SequenceTagger predicts: Dictionary with 25 tags: O, S-Funding Agency, B-Funding Agency, E-Funding Agency, I-Funding Agency, S-Grant Number, B-Grant Number, E-Grant Number, I-Grant Number, S-Person, B-Person, E-Person, I-Person, S-University, B-University, E-University, I-University, S-Miscellaneous, B-Miscellaneous, E-Miscellaneous, I-Miscellaneous, S-Corporation, B-Corporation, E-Corporation, I-Corporation
100%|██████████| 3/3 [13:01<00:00, 260.65s/it]
2023-12-10 22:02:39,947 
Results:
- F-score (micro) 0.7924
- F-score (macro) 0.726
- Accuracy 0.6739

By class:
                precision    recall  f1-score   support

        Person     0.8942    0.9458    0.9193       295
  Grant Number     0.8844    0.9563    0.9189       160
Funding Agency     0.7110    0.7834    0.7455       157
    University     0.5455    0.5455    0.5455        99
 Miscellaneous     0.4706    0.3902    0.4267        82
   Corporation     1.0000    0.6667    0.8000        12

     micro avg     0.7791    0.8062    0.7924       805
     macro avg     0.7509    0.7146    0.7260       805
  weighted avg     0.7721    0.8062    0.7874       805

2023-12-10 22:02:39,950 ----------------------------------------------------------------------------------------------------

{'test_score': 0.7924297924297924}