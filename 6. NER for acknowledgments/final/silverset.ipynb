{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482aab8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a44ed07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_path = 'data/corpus_silver/new_acknowledgements.csv'\n",
    "\n",
    "with open(csv_file_path, 'r', encoding = 'ISO-8859-1') as file:\n",
    "    csv_reader = csv.reader(file,delimiter=';')\n",
    "    header = next(csv_reader)\n",
    "    \n",
    "    silver_text = []\n",
    "    for row in csv_reader:\n",
    "        silver_text.append(Sentence(row[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae53e04-f7da-4ac8-8e4a-2b04538e787f",
   "metadata": {},
   "source": [
    "Due to model size, it is stored on google drive https://drive.google.com/file/d/1zayPmVqdljP2176SvnsliraFAEabArdZ/view?usp=sharing. To run next cell you need to download it and replace the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ead8588",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-09 16:30:33,646 SequenceTagger predicts: Dictionary with 27 tags: O, S-Funding Agency, B-Funding Agency, E-Funding Agency, I-Funding Agency, S-Grant Number, B-Grant Number, E-Grant Number, I-Grant Number, S-Person, B-Person, E-Person, I-Person, S-University, B-University, E-University, I-University, S-Miscellaneous, B-Miscellaneous, E-Miscellaneous, I-Miscellaneous, S-Corporation, B-Corporation, E-Corporation, I-Corporation, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "model = SequenceTagger.load(\"models/flair_corp4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dffbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_silver_standard_txt(path):\n",
    "    model.predict(silver_text)\n",
    "    \n",
    "    label_map = {'Funding Agency':'FUND',\n",
    "                  'Person':'IND',\n",
    "                  'Corporation':'COR',\n",
    "                  'Grant Number':'GRNB',\n",
    "                  'University':'UNI',\n",
    "                  'Miscellaneous':'MISC'\n",
    "                  }\n",
    "    \n",
    "    with open(path, \"w\") as f:\n",
    "        for sentence in silver_text:\n",
    "            for entity in sentence.get_spans('ner'):\n",
    "                prefix = 'B-'\n",
    "                for token in entity:\n",
    "                    token.set_label('ner', prefix + label_map[entity.tag], entity.score)\n",
    "                    prefix = 'I-'\n",
    "\n",
    "            for token in sentence:\n",
    "                f.write(f\"{token.text} {token.get_label('ner').value}\")\n",
    "                f.write(\"\\n\")\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab739f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_silver_standard_txt(r'data/corpus1_silver/silver_set.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ee2a14-8cd4-40c5-badc-d1e008bc4204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus1_path = 'data/corpus1'\n",
    "corpus_silver_path = 'data/corpus1_silver'\n",
    "file_names = ['train.txt', 'dev.txt', 'test.txt']\n",
    "\n",
    "for file_name in file_names:\n",
    "    source_path = f'{corpus1_path}/{file_name}'\n",
    "    destination_path = f'{corpus_silver_path}/{file_name}'\n",
    "    shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "silver_set_path = f'{corpus_silver_path}/silver_set.txt'\n",
    "train_path = f'{corpus_silver_path}/train.txt'\n",
    "with open(train_path, 'a') as train_file, open(silver_set_path, 'r') as silver_set_file:\n",
    "    for line in silver_set_file:\n",
    "        train_file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbbc4472-a3aa-4ff7-acd9-614cd52ca449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('models/flair_corp1_silver4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf88270-20fd-43cc-8877-8fd57b5b76d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus4_path = 'data/corpus4'\n",
    "corpus_silver_path = 'data/corpus4_silver'\n",
    "file_names = ['train.txt', 'dev.txt', 'test.txt']\n",
    "\n",
    "for file_name in file_names:\n",
    "    source_path = f'{corpus4_path}/{file_name}'\n",
    "    destination_path = f'{corpus_silver_path}/{file_name}'\n",
    "    shutil.copyfile(source_path, destination_path)\n",
    "    \n",
    "shutil.copyfile('data/corpus1_silver/silver_set.txt','data/corpus4_silver/silver_set.txt')\n",
    "\n",
    "silver_set_path = f'data/corpus4_silver/silver_set.txt'\n",
    "train_path = f'data/corpus4_silver/train.txt'\n",
    "with open(train_path, 'a') as train_file, open(silver_set_path, 'r') as silver_set_file:\n",
    "    for line in silver_set_file:\n",
    "        train_file.write(line)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
